# backend/.env.example
# LEIA ESSE ARQUIVO -> Standards: docs/STANDARDS.md <- NÃO EDITE O CODIGO SEM CONHECIMENTO DESSE ARQUIVO (MUITO IMPORTANTE)

#############################################
# Server / Environment
#############################################
# Porta do servidor Express
PORT=3001
# Ambiente: development | production
NODE_ENV=development

#############################################
# Database (PostgreSQL com pgvector)
#############################################
# String de conexão (Prisma usa DATABASE_URL)
# Ex: postgresql://user:pass@localhost:5432/myia?schema=public
DATABASE_URL="postgresql://leonardo@localhost:5432/myia?schema=public"

#############################################
# Segurança: JWT / Criptografia
#############################################
# JWT (CRÍTICO) - Gere com:
# node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# Mínimo 32 bytes.
JWT_SECRET=sua-chave-criptografia-aqui
JWT_EXPIRES_IN=7d

# Secret para criptografia de chaves/segredos no DB
# Gere com o mesmo comando acima
ENCRYPTION_SECRET=sua-chave-criptografia-aqui

#############################################
# CORS / Frontend
#############################################
# Origens separadas por vírgula para dev 
CORS_ORIGIN=http://127.0.0.1:3000

# URL do frontend (Vite/React)
FRONTEND_URL=http://localhost:5173

#############################################
# Chat / Context Configuration
#############################################
# Quantidade máxima de mensagens por chat em memória
MAX_CONTEXT_MESSAGES=15
# Intervalo (ms) para limpeza de contextos/processos agendados
CONTEXT_CLEANUP_INTERVAL=3600000

#############################################
# Default AI Provider (se não especificado pela requisição)
#############################################
# Valores possíveis: groq, openai, together, perplexity, mistral, anthropic, azure, aws_bedrock
API_PROVIDER=groq

#############################################
# Providers (Chaves e Modelos)
#############################################
# OpenAI (ex: gpt-3.5-turbo, gpt-4)
OPENAI_API_KEY=sk-proj-sua-chave-aqui
OPENAI_MODEL=gpt-3.5-turbo

# GROQ (opcional)
GROQ_API_KEY=sua-chave-groq-aqui
GROQ_MODEL=llama-3.1-8b-instant

#############################################
# Azure OpenAI (RAG - Embeddings) 
#############################################
# Endpoint: https://seu-recurso.openai.azure.com (SEM /deployments no final)
AZURE_EMBEDDING_ENDPOINT="https://seu-recurso.openai.azure.com"
# API Key do Azure (não é a mesma chave da OpenAI normal)
AZURE_API_KEY="sua_chave_azure_aqui"
# Nome do deployment criado no Azure (ex: text-embedding-3-small)
AZURE_EMBEDDING_DEPLOYMENT_NAME="text-embedding-3-small"

#############################################
# AWS Bedrock 
#############################################
# Formato: ACCESS_KEY:SECRET_KEY
# Exemplo: AKIAIOSFODNN7EXAMPLE:wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_BEDROCK_CREDENTIALS=sua-access-key:sua-secret-key
AWS_BEDROCK_REGION=us-east-1

#############################################
# OAuth / Third-party
#############################################
# GitHub OAuth 
GITHUB_CLIENT_ID="Iv1.1234567890abcdef"
GITHUB_CLIENT_SECRET="abcdef1234567890abcdef1234567890abcdef12"
GITHUB_OAUTH_CALLBACK_URL="http://localhost:3001/api/auth/github/callback"

#############################################
# Observações / Boas práticas
#############################################
# - NÃO coloque chaves reais neste arquivo no repositório.
# - Use um arquivo local .env (gitignored) ou um secret manager em produção.
# - Gere segredos com: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# - Variáveis opcionais podem ser removidas se não forem usadas pelo seu provedor.