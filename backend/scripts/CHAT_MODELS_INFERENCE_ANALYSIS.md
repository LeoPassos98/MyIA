# An√°lise de Modelos de Chat - Inference Profiles

**Data da An√°lise:** 2026-01-30T13:40:12.869Z

## üìä Resumo Executivo

- **Total de modelos de CHAT:** 58
- **Modelos MODERNOS:** 13
- **Modelos OBSOLETOS:** 45
- **Com Inference Profile:** 21 (36.2%)
- **Requerem Inference Profile:** 6

---

## ‚ú® Modelos de Chat MODERNOS


### ‚ö™ openai.gpt-oss-120b-1:0

- **Provider:** OpenAI
- **Nome:** gpt-oss-120b
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.voxtral-mini-3b-2507

- **Provider:** Mistral AI
- **Nome:** Voxtral Mini 3B 2507
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.mistral-large-3-675b-instruct

- **Provider:** Mistral AI
- **Nome:** Mistral Large 3
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.ministral-3-14b-instruct

- **Provider:** Mistral AI
- **Nome:** Ministral 14B 3.0
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.ministral-3-8b-instruct

- **Provider:** Mistral AI
- **Nome:** Ministral 3 8B
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.voxtral-small-24b-2507

- **Provider:** Mistral AI
- **Nome:** Voxtral Small 24B 2507
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ openai.gpt-oss-20b-1:0

- **Provider:** OpenAI
- **Nome:** gpt-oss-20b
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ openai.gpt-oss-safeguard-120b

- **Provider:** OpenAI
- **Nome:** GPT OSS Safeguard 120B
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.magistral-small-2509

- **Provider:** Mistral AI
- **Nome:** Magistral Small 2509
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.ministral-3-3b-instruct

- **Provider:** Mistral AI
- **Nome:** Ministral 3B
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ openai.gpt-oss-safeguard-20b

- **Provider:** OpenAI
- **Nome:** GPT OSS Safeguard 20B
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.mistral-7b-instruct-v0:2

- **Provider:** Mistral AI
- **Nome:** Mistral 7B Instruct
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


### ‚ö™ mistral.mixtral-8x7b-instruct-v0:1

- **Provider:** Mistral AI
- **Nome:** Mixtral 8x7B Instruct
- **Inference Profile:** N√ÉO SUPORTA
- **Inference Types:** ON_DEMAND
- **Modalities:** TEXT


---

## üóëÔ∏è Modelos de Chat OBSOLETOS

- anthropic.claude-sonnet-4-20250514-v1:0 (Anthropic) - Suporta Profile
- anthropic.claude-haiku-4-5-20251001-v1:0 (Anthropic) - Suporta Profile
- amazon.nova-pro-v1:0 (Amazon) - Suporta Profile
- amazon.nova-2-lite-v1:0 (Amazon) - Suporta Profile
- amazon.nova-2-lite-v1:0:256k (Amazon) - N√£o suporta
- amazon.nova-2-sonic-v1:0 (Amazon) - N√£o suporta
- anthropic.claude-sonnet-4-5-20250929-v1:0 (Anthropic) - Suporta Profile
- anthropic.claude-opus-4-1-20250805-v1:0 (Anthropic) - Suporta Profile
- anthropic.claude-opus-4-5-20251101-v1:0 (Anthropic) - Suporta Profile
- amazon.nova-premier-v1:0:8k (Amazon) - N√£o suporta
- amazon.nova-premier-v1:0:20k (Amazon) - N√£o suporta
- amazon.nova-premier-v1:0:1000k (Amazon) - N√£o suporta
- amazon.nova-premier-v1:0:mm (Amazon) - N√£o suporta
- amazon.nova-premier-v1:0 (Amazon) - Suporta Profile
- amazon.nova-pro-v1:0:24k (Amazon) - N√£o suporta
- amazon.nova-pro-v1:0:300k (Amazon) - N√£o suporta
- amazon.nova-lite-v1:0:24k (Amazon) - N√£o suporta
- amazon.nova-lite-v1:0:300k (Amazon) - N√£o suporta
- amazon.nova-lite-v1:0 (Amazon) - Suporta Profile
- amazon.nova-micro-v1:0:24k (Amazon) - N√£o suporta
- amazon.nova-micro-v1:0:128k (Amazon) - N√£o suporta
- amazon.nova-micro-v1:0 (Amazon) - Suporta Profile
- amazon.nova-sonic-v1:0 (Amazon) - N√£o suporta
- ai21.jamba-1-5-large-v1:0 (AI21 Labs) - N√£o suporta
- ai21.jamba-1-5-mini-v1:0 (AI21 Labs) - N√£o suporta
- anthropic.claude-3-haiku-20240307-v1:0:48k (Anthropic) - N√£o suporta
- anthropic.claude-3-haiku-20240307-v1:0:200k (Anthropic) - N√£o suporta
- anthropic.claude-3-haiku-20240307-v1:0 (Anthropic) - N√£o suporta
- anthropic.claude-3-5-haiku-20241022-v1:0 (Anthropic) - Suporta Profile
- cohere.command-r-v1:0 (Cohere) - N√£o suporta
- cohere.command-r-plus-v1:0 (Cohere) - N√£o suporta
- meta.llama3-8b-instruct-v1:0 (Meta) - N√£o suporta
- meta.llama3-70b-instruct-v1:0 (Meta) - N√£o suporta
- meta.llama3-1-8b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama3-1-70b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama3-2-11b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama3-2-90b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama3-2-1b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama3-2-3b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama3-3-70b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama4-scout-17b-instruct-v1:0 (Meta) - Suporta Profile
- meta.llama4-maverick-17b-instruct-v1:0 (Meta) - Suporta Profile
- mistral.mistral-large-2402-v1:0 (Mistral AI) - N√£o suporta
- mistral.mistral-small-2402-v1:0 (Mistral AI) - N√£o suporta
- mistral.pixtral-large-2502-v1:0 (Mistral AI) - Suporta Profile

---

## üéØ Conclus√£o

‚ö†Ô∏è Hip√≥tese parcialmente correta. An√°lise mais detalhada necess√°ria.

---

## üìä Dados Completos (JSON)

```json
[
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-sonnet-4-20250514-v1:0",
    "modelName": "Claude Sonnet 4",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": true,
    "testResult": "REQUIRES_PROFILE",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-haiku-4-5-20251001-v1:0",
    "modelName": "Claude Haiku 4.5",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": true,
    "testResult": "REQUIRES_PROFILE",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "OpenAI",
    "modelId": "openai.gpt-oss-120b-1:0",
    "modelName": "gpt-oss-120b",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.voxtral-mini-3b-2507",
    "modelName": "Voxtral Mini 3B 2507",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-pro-v1:0",
    "modelName": "Nova Pro",
    "supportsInferenceProfile": true,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND",
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-2-lite-v1:0",
    "modelName": "Nova 2 Lite",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-2-lite-v1:0:256k",
    "modelName": "Nova 2 Lite",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.mistral-large-3-675b-instruct",
    "modelName": "Mistral Large 3",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-2-sonic-v1:0",
    "modelName": "Nova 2 Sonic",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "SPEECH",
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.ministral-3-14b-instruct",
    "modelName": "Ministral 14B 3.0",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.ministral-3-8b-instruct",
    "modelName": "Ministral 3 8B",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.voxtral-small-24b-2507",
    "modelName": "Voxtral Small 24B 2507",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "OpenAI",
    "modelId": "openai.gpt-oss-20b-1:0",
    "modelName": "gpt-oss-20b",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "OpenAI",
    "modelId": "openai.gpt-oss-safeguard-120b",
    "modelName": "GPT OSS Safeguard 120B",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-sonnet-4-5-20250929-v1:0",
    "modelName": "Claude Sonnet 4.5",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": true,
    "testResult": "REQUIRES_PROFILE",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-opus-4-1-20250805-v1:0",
    "modelName": "Claude Opus 4.1",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": true,
    "testResult": "REQUIRES_PROFILE",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.magistral-small-2509",
    "modelName": "Magistral Small 2509",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.ministral-3-3b-instruct",
    "modelName": "Ministral 3B",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-opus-4-5-20251101-v1:0",
    "modelName": "Claude Opus 4.5",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": true,
    "testResult": "REQUIRES_PROFILE",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "OpenAI",
    "modelId": "openai.gpt-oss-safeguard-20b",
    "modelName": "GPT OSS Safeguard 20B",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-premier-v1:0:8k",
    "modelName": "Nova Premier",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-premier-v1:0:20k",
    "modelName": "Nova Premier",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-premier-v1:0:1000k",
    "modelName": "Nova Premier",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-premier-v1:0:mm",
    "modelName": "Nova Premier",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-premier-v1:0",
    "modelName": "Nova Premier",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-pro-v1:0:24k",
    "modelName": "Nova Pro",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-pro-v1:0:300k",
    "modelName": "Nova Pro",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-lite-v1:0:24k",
    "modelName": "Nova Lite",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-lite-v1:0:300k",
    "modelName": "Nova Lite",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-lite-v1:0",
    "modelName": "Nova Lite",
    "supportsInferenceProfile": true,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND",
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-micro-v1:0:24k",
    "modelName": "Nova Micro",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-micro-v1:0:128k",
    "modelName": "Nova Micro",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-micro-v1:0",
    "modelName": "Nova Micro",
    "supportsInferenceProfile": true,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND",
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Amazon",
    "modelId": "amazon.nova-sonic-v1:0",
    "modelName": "Nova Sonic",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "SPEECH",
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "AI21 Labs",
    "modelId": "ai21.jamba-1-5-large-v1:0",
    "modelName": "Jamba 1.5 Large",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "AI21 Labs",
    "modelId": "ai21.jamba-1-5-mini-v1:0",
    "modelName": "Jamba 1.5 Mini",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-3-haiku-20240307-v1:0:48k",
    "modelName": "Claude 3 Haiku",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "ERROR: Model not found.",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-3-haiku-20240307-v1:0:200k",
    "modelName": "Claude 3 Haiku",
    "supportsInferenceProfile": false,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "ERROR: Model not found.",
    "inferenceTypes": [
      "PROVISIONED"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-3-haiku-20240307-v1:0",
    "modelName": "Claude 3 Haiku",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "WORKS_WITHOUT_PROFILE",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Anthropic",
    "modelId": "anthropic.claude-3-5-haiku-20241022-v1:0",
    "modelName": "Claude 3.5 Haiku",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": true,
    "testResult": "REQUIRES_PROFILE",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Cohere",
    "modelId": "cohere.command-r-v1:0",
    "modelName": "Command R",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Cohere",
    "modelId": "cohere.command-r-plus-v1:0",
    "modelName": "Command R+",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-8b-instruct-v1:0",
    "modelName": "Llama 3 8B Instruct",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-70b-instruct-v1:0",
    "modelName": "Llama 3 70B Instruct",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-1-8b-instruct-v1:0",
    "modelName": "Llama 3.1 8B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-1-70b-instruct-v1:0",
    "modelName": "Llama 3.1 70B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-2-11b-instruct-v1:0",
    "modelName": "Llama 3.2 11B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-2-90b-instruct-v1:0",
    "modelName": "Llama 3.2 90B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-2-1b-instruct-v1:0",
    "modelName": "Llama 3.2 1B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-2-3b-instruct-v1:0",
    "modelName": "Llama 3.2 3B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama3-3-70b-instruct-v1:0",
    "modelName": "Llama 3.3 70B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama4-scout-17b-instruct-v1:0",
    "modelName": "Llama 4 Scout 17B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Meta",
    "modelId": "meta.llama4-maverick-17b-instruct-v1:0",
    "modelName": "Llama 4 Maverick 17B Instruct",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.mistral-7b-instruct-v0:2",
    "modelName": "Mistral 7B Instruct",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.mixtral-8x7b-instruct-v0:1",
    "modelName": "Mixtral 8x7B Instruct",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": false,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.mistral-large-2402-v1:0",
    "modelName": "Mistral Large (24.02)",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.mistral-small-2402-v1:0",
    "modelName": "Mistral Small (24.02)",
    "supportsInferenceProfile": false,
    "supportsOnDemand": true,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "ON_DEMAND"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  },
  {
    "provider": "Mistral AI",
    "modelId": "mistral.pixtral-large-2502-v1:0",
    "modelName": "Pixtral Large (25.02)",
    "supportsInferenceProfile": true,
    "supportsOnDemand": false,
    "requiresProfile": false,
    "testResult": "NOT_TESTED",
    "inferenceTypes": [
      "INFERENCE_PROFILE"
    ],
    "modalities": [
      "TEXT"
    ],
    "isObsolete": true,
    "isChatModel": true
  }
]
```

---

**Gerado por:** analyze-chat-models-profiles.ts  
**Timestamp:** 2026-01-30T13:40:12.869Z
