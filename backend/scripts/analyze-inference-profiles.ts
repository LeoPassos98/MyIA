import { BedrockClient, ListFoundationModelsCommand } from '@aws-sdk/client-bedrock';
import { BedrockRuntimeClient, InvokeModelCommand } from '@aws-sdk/client-bedrock-runtime';
import dotenv from 'dotenv';

// Carregar vari√°veis de ambiente
dotenv.config();

interface ModelAnalysis {
  provider: string;
  modelId: string;
  modelName?: string;
  supportsInferenceProfile: boolean;
  supportsOnDemand: boolean;
  requiresProfile: boolean;
  testResult: string;
  inferenceTypes: string[];
}

async function analyzeInferenceProfiles() {
  console.log('üîç Analisando requisitos de Inference Profiles...\n');

  // Extrair credenciais do formato ACCESS_KEY:SECRET_KEY
  const credentials = process.env.AWS_BEDROCK_CREDENTIALS;
  if (!credentials) {
    console.error('‚ùå AWS_BEDROCK_CREDENTIALS n√£o encontrado no .env');
    return;
  }

  const [accessKeyId, secretAccessKey] = credentials.split(':');
  if (!accessKeyId || !secretAccessKey) {
    console.error('‚ùå Formato inv√°lido de AWS_BEDROCK_CREDENTIALS. Esperado: ACCESS_KEY:SECRET_KEY');
    return;
  }

  const region = process.env.AWS_BEDROCK_REGION || 'us-east-1';
  console.log(`üìç Regi√£o: ${region}`);
  console.log(`üîë Access Key: ${accessKeyId.substring(0, 8)}...`);
  console.log('');

  const bedrockClient = new BedrockClient({
    region,
    credentials: {
      accessKeyId,
      secretAccessKey,
    },
  });

  const runtimeClient = new BedrockRuntimeClient({
    region,
    credentials: {
      accessKeyId,
      secretAccessKey,
    },
  });

  try {
    // 1. Listar modelos dispon√≠veis
    console.log('üì• Listando modelos dispon√≠veis...\n');
    const command = new ListFoundationModelsCommand({});
    const response = await bedrockClient.send(command);

    if (!response.modelSummaries) {
      console.log('‚ùå Nenhum modelo encontrado');
      return;
    }

    // 2. Filtrar apenas modelos ACTIVE
    const activeModels = response.modelSummaries.filter(
      m => m.modelLifecycle?.status === 'ACTIVE'
    );

    console.log(`üìä Total de modelos encontrados: ${response.modelSummaries.length}`);
    console.log(`üìä Total de modelos ACTIVE: ${activeModels.length}\n`);

    // 3. Agrupar por provider
    const byProvider: Record<string, any[]> = {};
    for (const model of activeModels) {
      const provider = model.providerName || 'Unknown';
      if (!byProvider[provider]) {
        byProvider[provider] = [];
      }
      byProvider[provider].push(model);
    }

    // 4. Analisar cada provider
    const results: ModelAnalysis[] = [];
    
    for (const [provider, models] of Object.entries(byProvider)) {
      console.log(`\nüè¢ ${provider} (${models.length} modelos):`);
      console.log('‚îÄ'.repeat(80));
      
      for (const model of models) {
        const modelId = model.modelId!;
        const modelName = model.modelName || 'N/A';
        const inferenceTypes = model.inferenceTypesSupported || [];
        
        // Verificar se suporta INFERENCE_PROFILE
        const supportsInferenceProfile = inferenceTypes.includes('INFERENCE_PROFILE');
        const supportsOnDemand = inferenceTypes.includes('ON_DEMAND');
        
        // Testar modelo
        let testResult = 'NOT_TESTED';
        let requiresProfile = false;
        
        // Apenas testar modelos Anthropic (Claude)
        if (provider === 'Anthropic' && modelId.includes('claude')) {
          try {
            console.log(`   üß™ Testando ${modelId}...`);
            await testModel(runtimeClient, modelId);
            testResult = 'WORKS_WITHOUT_PROFILE';
            console.log(`   ‚úÖ Funciona sem inference profile`);
          } catch (error: any) {
            const errorMsg = error.message || String(error);
            if (errorMsg.includes('on-demand throughput') || 
                errorMsg.includes('inference profile') ||
                errorMsg.includes('not available')) {
              requiresProfile = true;
              testResult = 'REQUIRES_PROFILE';
              console.log(`   üî¥ REQUER INFERENCE PROFILE`);
            } else {
              testResult = `ERROR: ${errorMsg.substring(0, 100)}`;
              console.log(`   ‚ö†Ô∏è  Erro: ${errorMsg.substring(0, 100)}`);
            }
          }
        }
        
        results.push({
          provider,
          modelId,
          modelName,
          supportsInferenceProfile,
          supportsOnDemand,
          requiresProfile,
          testResult,
          inferenceTypes,
        });
        
        const emoji = requiresProfile ? 'üî¥' : supportsInferenceProfile ? 'üü°' : '‚úÖ';
        console.log(`${emoji} ${modelId}`);
        console.log(`   Nome: ${modelName}`);
        console.log(`   Inference Types: ${inferenceTypes.join(', ') || 'Nenhum'}`);
        if (requiresProfile) {
          console.log(`   ‚ö†Ô∏è  REQUER INFERENCE PROFILE`);
        }
        console.log('');
      }
    }

    // 5. Gerar relat√≥rio
    generateReport(results);
    
    // 6. Salvar relat√≥rio em arquivo
    await saveReportToFile(results);

  } catch (error) {
    console.error('‚ùå Erro ao analisar modelos:', error);
    throw error;
  }
}

async function testModel(client: BedrockRuntimeClient, modelId: string): Promise<void> {
  const command = new InvokeModelCommand({
    modelId,
    body: JSON.stringify({
      anthropic_version: 'bedrock-2023-05-31',
      messages: [{ role: 'user', content: 'test' }],
      max_tokens: 10,
    }),
  });
  
  await client.send(command);
}

function generateReport(results: ModelAnalysis[]) {
  console.log('\n\n');
  console.log('='.repeat(80));
  console.log('üìä RELAT√ìRIO DE INFERENCE PROFILES');
  console.log('='.repeat(80));
  
  const requiresProfile = results.filter(r => r.requiresProfile);
  const supportsProfile = results.filter(r => r.supportsInferenceProfile);
  const byProvider = groupByProvider(results);
  
  console.log(`\nüìà ESTAT√çSTICAS GERAIS:`);
  console.log(`   Total de modelos analisados: ${results.length}`);
  console.log(`   Modelos que REQUEREM Inference Profile: ${requiresProfile.length}`);
  console.log(`   Modelos que SUPORTAM Inference Profile: ${supportsProfile.length}`);
  console.log(`   Modelos que N√ÉO precisam: ${results.length - supportsProfile.length}`);
  
  console.log(`\n\nüî¥ MODELOS QUE REQUEREM INFERENCE PROFILE (${requiresProfile.length}):`);
  console.log('‚îÄ'.repeat(80));
  if (requiresProfile.length > 0) {
    for (const model of requiresProfile) {
      console.log(`   - ${model.modelId}`);
      console.log(`     Provider: ${model.provider}`);
      console.log(`     Nome: ${model.modelName}`);
      console.log(`     Inference Types: ${model.inferenceTypes.join(', ')}`);
      console.log('');
    }
  } else {
    console.log('   Nenhum modelo requer inference profile obrigatoriamente.');
  }
  
  console.log(`\nüü° MODELOS QUE SUPORTAM INFERENCE PROFILE (${supportsProfile.length}):`);
  console.log('‚îÄ'.repeat(80));
  const supportsButNotRequires = supportsProfile.filter(m => !m.requiresProfile);
  if (supportsButNotRequires.length > 0) {
    for (const model of supportsButNotRequires) {
      console.log(`   - ${model.modelId} (${model.provider})`);
    }
  } else {
    console.log('   Todos os modelos que suportam tamb√©m requerem.');
  }
  
  console.log(`\n\nüìã AN√ÅLISE POR PROVIDER:`);
  console.log('‚îÄ'.repeat(80));
  for (const [provider, models] of Object.entries(byProvider)) {
    const requires = models.filter(m => m.requiresProfile).length;
    const supports = models.filter(m => m.supportsInferenceProfile).length;
    console.log(`\n${provider}:`);
    console.log(`   Total: ${models.length}`);
    console.log(`   Requer Profile: ${requires}`);
    console.log(`   Suporta Profile: ${supports}`);
  }
  
  // Recomenda√ß√µes
  console.log('\n\nüìã RECOMENDA√á√ïES:');
  console.log('‚îÄ'.repeat(80));
  
  if (requiresProfile.length > 0) {
    console.log('\n1. ‚úÖ Adicionar `requires_inference_profile: true` para:');
    for (const model of requiresProfile) {
      console.log(`   - ${model.modelId}`);
    }
  } else {
    console.log('\n1. ‚úÖ Nenhum modelo requer inference profile obrigatoriamente');
  }
  
  console.log('\n2. üîß Atualizar bedrock.ts para:');
  console.log('   - Usar inference profile APENAS quando modelo requer');
  console.log('   - Manter modelId direto para modelos que n√£o requerem');
  console.log('   - Adicionar fallback inteligente');
  
  console.log('\n3. üìù Atualizar registry models para marcar modelos que requerem profile');
  
  console.log('\n4. üß™ Re-testar modelos ap√≥s corre√ß√µes');
  
  console.log('\n\n‚úÖ An√°lise conclu√≠da!');
  console.log('üìÑ Relat√≥rio salvo em: backend/scripts/INFERENCE_PROFILES_ANALYSIS.md');
}

function groupByProvider(results: ModelAnalysis[]): Record<string, ModelAnalysis[]> {
  const grouped: Record<string, ModelAnalysis[]> = {};
  for (const result of results) {
    if (!grouped[result.provider]) {
      grouped[result.provider] = [];
    }
    grouped[result.provider].push(result);
  }
  return grouped;
}

async function saveReportToFile(results: ModelAnalysis[]) {
  const fs = await import('fs/promises');
  const path = await import('path');
  
  const requiresProfile = results.filter(r => r.requiresProfile);
  const supportsProfile = results.filter(r => r.supportsInferenceProfile);
  const byProvider = groupByProvider(results);
  
  let markdown = `# An√°lise de Inference Profiles - AWS Bedrock

**Data da An√°lise:** ${new Date().toISOString()}

## üìä Resumo Executivo

- **Total de modelos analisados:** ${results.length}
- **Modelos que REQUEREM Inference Profile:** ${requiresProfile.length}
- **Modelos que SUPORTAM Inference Profile:** ${supportsProfile.length}
- **Modelos que N√ÉO precisam:** ${results.length - supportsProfile.length}

---

## üî¥ Modelos que REQUEREM Inference Profile

${requiresProfile.length > 0 ? requiresProfile.map(m => `
### ${m.modelId}

- **Provider:** ${m.provider}
- **Nome:** ${m.modelName}
- **Inference Types:** ${m.inferenceTypes.join(', ')}
- **Resultado do Teste:** ${m.testResult}
`).join('\n') : 'Nenhum modelo requer inference profile obrigatoriamente.'}

---

## üü° Modelos que SUPORTAM Inference Profile (mas n√£o requerem)

${supportsProfile.filter(m => !m.requiresProfile).map(m => `- ${m.modelId} (${m.provider})`).join('\n') || 'Todos os modelos que suportam tamb√©m requerem.'}

---

## üìã An√°lise por Provider

${Object.entries(byProvider).map(([provider, models]) => {
  const requires = models.filter(m => m.requiresProfile).length;
  const supports = models.filter(m => m.supportsInferenceProfile).length;
  return `
### ${provider}

- **Total de modelos:** ${models.length}
- **Requerem Profile:** ${requires}
- **Suportam Profile:** ${supports}

**Modelos:**
${models.map(m => {
  const emoji = m.requiresProfile ? 'üî¥' : m.supportsInferenceProfile ? 'üü°' : '‚úÖ';
  return `- ${emoji} \`${m.modelId}\` - ${m.modelName}`;
}).join('\n')}
`;
}).join('\n')}

---

## üìã Recomenda√ß√µes

### 1. Atualizar Registry Models

${requiresProfile.length > 0 ? `Adicionar \`requires_inference_profile: true\` para:

${requiresProfile.map(m => `- \`${m.modelId}\``).join('\n')}
` : 'Nenhuma atualiza√ß√£o necess√°ria - nenhum modelo requer inference profile obrigatoriamente.'}

### 2. Atualizar bedrock.ts

- Usar inference profile APENAS quando modelo requer
- Manter modelId direto para modelos que n√£o requerem
- Adicionar fallback inteligente

### 3. Pr√≥ximos Passos

1. ‚úÖ Revisar configura√ß√£o atual do registry
2. ‚úÖ Atualizar modelos que requerem profile
3. ‚úÖ Testar modelos ap√≥s corre√ß√µes
4. ‚úÖ Validar funcionamento em produ√ß√£o

---

## üìä Dados Completos

\`\`\`json
${JSON.stringify(results, null, 2)}
\`\`\`

---

**Gerado por:** analyze-inference-profiles.ts
**Timestamp:** ${new Date().toISOString()}
`;

  const reportPath = path.join(process.cwd(), 'scripts', 'INFERENCE_PROFILES_ANALYSIS.md');
  await fs.writeFile(reportPath, markdown, 'utf-8');
  console.log(`\nüìÑ Relat√≥rio salvo em: ${reportPath}`);
}

// Executar an√°lise
analyzeInferenceProfiles().catch(console.error);
