import { Response, NextFunction } from 'express';
import { AuthRequest } from '../middleware/authMiddleware';
import { aiService } from '../services/ai';
import { ProviderName, TelemetryMetrics, StreamChunk, AiServiceResponse } from '../services/ai/types';
import { logger } from '../utils/logger';
import { prisma } from '../lib/prisma';
import { get_encoding } from 'tiktoken';
import { getProviderInfo } from '../config/providerMap';
import { getProviderConfig } from '../services/ai/utils/providerUtils';

// Instanciar encoding tiktoken (escopo global)
const encoding = get_encoding('cl100k_base');


// Helper: conta palavras
function countWords(str: string): number {
  if (!str) return 0;
  return str.split(/\s+/).filter(Boolean).length;
}

// Helper: cria timeout reutiliz√°vel
function createTimeout(ms: number, message: string): Promise<never> {
  return new Promise((_, reject) => {
    setTimeout(() => {
      reject(new Error(message));
    }, ms);
  });
}

// --- MOTOR 1 (V7 - R√°pido/Burro) ---
async function getFastHistory(chatId: string) {
  const messages = await prisma.message.findMany({
    where: { chatId },
    orderBy: { createdAt: 'desc' }, // Descendente para pegar os mais novos
    take: 10, // O "N√∫mero M√°gico"
  });
  // Reverter ordem para asc (mais velho ‚Üí mais novo)
  return messages.reverse();
}

// --- MOTOR 2 (V12 - Eficiente/DIN√ÇMICO) ---
async function getEfficientHistory(
  chatId: string, 
  userMessage: string, 
  providerModel: string // ex: 'llama-3.1-8b-instant'
) {
  
  // 1. Pegar a "Mochila" (O Limite Din√¢mico)
  const providerInfo = getProviderInfo(providerModel);

  // 2. Definir o "Or√ßamento" (Deixando espa√ßo para a resposta)
  const ANSWER_BUFFER = 2000; // Reserva 2k tokens para a IA responder
  const MAX_CONTEXT_TOKENS = providerInfo.contextLimit - ANSWER_BUFFER;

  // 3. Or√ßamento Inicial (Prioriza a mensagem do usu√°rio)
  const messageTokens = encoding.encode(userMessage).length;
  let budget = MAX_CONTEXT_TOKENS - messageTokens;

  // 4. Buscar *todo* o hist√≥rico (do mais novo para o mais velho)
  const allMessages = await prisma.message.findMany({
    where: { chatId },
    orderBy: { createdAt: 'desc' },
  });

  const contextHistory = [];
  for (const msg of allMessages) {
    const tokens = encoding.encode(msg.content).length;

    if (budget - tokens >= 0) {
      // O "Fiscal" diz: "Cabe na mochila!"
      budget -= tokens;
      contextHistory.push(msg);
    } else {
      // A "Mochila" est√° cheia. Pare de adicionar.
      break;
    }
  }

  // Reverter ordem para asc (mais velho ‚Üí mais novo)
  return contextHistory.reverse();
}

export const chatController = {
  async sendMessage(req: AuthRequest, res: Response, next: NextFunction) {
    try {
      if (!req.userId) {
        return res.status(401).json({ error: 'Unauthorized' });
      }

      const { message, provider: requestProvider, chatId, contextStrategy } = req.body;

      // Validar provider se fornecido
      const validProviders: ProviderName[] = ['openai', 'groq', 'together', 'perplexity', 'mistral', 'claude'];
      
      if (requestProvider && !validProviders.includes(requestProvider)) {
        return res.status(400).json({ 
          error: `Invalid provider. Valid options: ${validProviders.join(', ')}` 
        });
      }

      // --- Configurar Headers SSE ---
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');
      res.flushHeaders(); // Envia headers imediatamente

      // Helper: Escrever evento SSE
      const writeSSE = (data: StreamChunk) => {
        res.write(`data: ${JSON.stringify(data)}\n\n`);
      };

      writeSSE({ type: 'debug', log: 'üîç Iniciando processamento da mensagem...' });

      // --- 1. Encontrar ou Criar a Conversa (Chat) ---
      writeSSE({ type: 'debug', log: 'üìã Validando usu√°rio...' });
      
      // --- Validar usu√°rio ---
      if (!req.userId) {
        return res.status(401).json({ error: 'Unauthorized' });
      }

      writeSSE({ type: 'debug', log: `üí¨ Chat ID: ${chatId || 'novo'}` });
      
      let currentChat;
      let lockedProvider: ProviderName;
      let isNewChat = false;

      if (chatId) {
        writeSSE({ type: 'debug', log: 'üîç Buscando chat existente...' });
        currentChat = await prisma.chat.findUnique({ 
          where: { id: chatId, userId: req.userId }
        });
        
        if (!currentChat) {
          writeSSE({ type: 'debug', log: '‚ùå Chat n√£o encontrado!' });
          writeSSE({ type: 'error', error: 'Conversa n√£o encontrada' });
          res.end();
          return;
        }
        
        lockedProvider = currentChat.provider as ProviderName;
        writeSSE({ type: 'debug', log: `üîí Provider travado: ${lockedProvider}` });
      } else {
        writeSSE({ type: 'debug', log: '‚ú® Criando novo chat...' });
        const providerToLock: ProviderName = requestProvider || 'groq';
        
        currentChat = await prisma.chat.create({
          data: {
            userId: req.userId,
            // Usa t√≠tulo padr√£o do schema - ser√° substitu√≠do depois
            provider: providerToLock
          }
        });
        
        lockedProvider = providerToLock;
        isNewChat = true;
        writeSSE({ type: 'debug', log: `‚úÖ Chat criado: ${currentChat.id} (provider: ${lockedProvider})` });
      }

      // --- 2. Salvar a Mensagem do Usu√°rio ---
      writeSSE({ type: 'debug', log: 'üíæ Salvando mensagem do usu√°rio no banco...' });
      await prisma.message.create({
        data: {
          role: 'user',
          content: message,
          chatId: currentChat.id,
        }
      });
      writeSSE({ type: 'debug', log: '‚úÖ Mensagem do usu√°rio salva!' });

      // --- 3. Preparar o Hist√≥rico para a IA ---
      writeSSE({ type: 'debug', log: 'üìö Buscando hist√≥rico de mensagens...' });
      
      writeSSE({ type: 'debug', log: `‚öôÔ∏è Estrat√©gia de Contexto: ${contextStrategy || 'fast'}` });

      // --- O "DISTRIBUIDOR" V12 ---
      
      // Precisamos do NOME DO MODELO, n√£o s√≥ do 'lockedProvider'
      const providerConfig = getProviderConfig(lockedProvider);
      const providerModel = providerConfig.defaultModel;

      writeSSE({ type: 'debug', log: `ü§ñ Provider: ${lockedProvider}, Modelo: ${providerModel}` });

      let historyMessages;

      if (contextStrategy === 'efficient') {
        const providerInfo = getProviderInfo(providerModel);
        writeSSE({ 
          type: 'debug', 
          log: `üß† Motor Eficiente (V12): Limite ${providerInfo.contextLimit} tokens, Buffer 2000` 
        });
        
        historyMessages = await getEfficientHistory(
          currentChat.id, 
          message, 
          providerModel // <-- A "Mochila" Din√¢mica
        );
      } else {
        writeSSE({ type: 'debug', log: '‚ö° Motor R√°pido (V7 - take: 10)...' });
        historyMessages = await getFastHistory(currentChat.id);
      }
      // --- FIM DO DISTRIBUIDOR ---

      const formattedMessages = historyMessages.map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content,
      }));
      writeSSE({ type: 'debug', log: `üìñ Hist√≥rico carregado: ${formattedMessages.length} mensagens` });

      // --- O NOVO MOTOR (Streaming com WATCHDOG) ---
      let watchdogTimer: NodeJS.Timeout | undefined;
      const WATCHDOG_TIMEOUT_MS = 60000;

      const resetWatchdog = () => {
        if (watchdogTimer) clearTimeout(watchdogTimer);
        watchdogTimer = setTimeout(() => {
          console.error("‚ö†Ô∏è WATCHDOG: Stream travado (60s sem chunks). Encerrando.");
          writeSSE({ type: 'debug', log: '‚è∞ TIMEOUT: 60s sem resposta da IA' });
          writeSSE({ type: 'error', error: 'Stream timeout: A API parou de responder.' });
          res.end();
        }, WATCHDOG_TIMEOUT_MS);
      };

      try {
        writeSSE({ type: 'debug', log: `ü§ñ Iniciando stream com ${lockedProvider}...` });
        const stream = aiService.stream(formattedMessages, lockedProvider);
        resetWatchdog();
        writeSSE({ type: 'debug', log: '‚è∞ Watchdog ativado (60s)' });

        let fullAssistantResponse = "";
        let finalMetrics: TelemetryMetrics | null = null;
        let chunkCount = 0;

        // "Sugue" o gotejamento do aiService
        for await (const chunk of stream) {
          resetWatchdog();

          if (chunk.type === 'chunk') {
            chunkCount++;
            // Opcional: muito verboso
            // writeSSE({ type: 'debug', log: `üì¶ Chunk #${chunkCount}: ${chunk.content.length} caracteres` });
          } else if (chunk.type === 'telemetry') {
            writeSSE({ type: 'debug', log: `üìä Telemetria recebida: ${chunk.metrics.tokensOut} tokens, $${chunk.metrics.costInUSD.toFixed(6)}` });
          }

          writeSSE(chunk);

          // Acumula dados para salvar no DB
          if (chunk.type === 'chunk') {
            fullAssistantResponse += chunk.content;
          } else if (chunk.type === 'telemetry') {
            finalMetrics = chunk.metrics;
          } else if (chunk.type === 'error') {
            writeSSE({ type: 'debug', log: `‚ùå Erro da IA: ${chunk.error}` });
          }
        }

        if (watchdogTimer) clearTimeout(watchdogTimer);
        writeSSE({ type: 'debug', log: `‚úÖ Stream finalizado! Total: ${chunkCount} chunks` });

        // --- O STREAM TERMINOU ---
        if (finalMetrics) {
          writeSSE({ type: 'debug', log: 'üíæ Salvando resposta completa no banco...' });
          
          await prisma.message.create({
            data: {
              role: 'assistant',
              content: fullAssistantResponse,
              chatId: currentChat.id,
              provider: finalMetrics.provider,
              model: finalMetrics.model,
              tokensIn: finalMetrics.tokensIn,
              tokensOut: finalMetrics.tokensOut,
              costInUSD: finalMetrics.costInUSD,
            }
          });
          writeSSE({ type: 'debug', log: '‚úÖ Resposta salva!' });

          // Calcular m√©tricas de engenharia
          const outputWords = countWords(fullAssistantResponse);
          const outputBytes = Buffer.byteLength(fullAssistantResponse, 'utf8');
          const inputWords = countWords(message);
          const inputBytes = Buffer.byteLength(message, 'utf8');

          writeSSE({ type: 'debug', log: 'üìà Salvando analytics...' });
          prisma.apiCallLog.create({
            data: {
              userId: req.userId!,
              provider: finalMetrics.provider,
              model: finalMetrics.model,
              tokensIn: finalMetrics.tokensIn,
              tokensOut: finalMetrics.tokensOut,
              costInUSD: finalMetrics.costInUSD,
              wordsIn: inputWords,
              wordsOut: outputWords,
              bytesIn: inputBytes,
              bytesOut: outputBytes,
            }
          }).catch(logErr => {
            console.error("Falha ao salvar log de analytics:", logErr);
            writeSSE({ type: 'debug', log: '‚ö†Ô∏è Erro ao salvar analytics (n√£o-cr√≠tico)' });
          });

          logger.info(`Stream completo para user ${req.userId} usando ${lockedProvider}`);
          writeSSE({ type: 'debug', log: '‚úÖ Analytics salvo!' });

        } else {
          writeSSE({ type: 'debug', log: '‚ö†Ô∏è Stream sem telemetria!' });
        }

        // --- Gera√ß√£o de T√≠tulo (Fire-and-Forget com TIMEOUT) ---
        if (isNewChat && currentChat.title === "Nova Conversa") {
          writeSSE({ type: 'debug', log: 'üè∑Ô∏è Iniciando gera√ß√£o de t√≠tulo (fire-and-forget)...' });
          
          (async () => {
            const groqModelName = 'llama-3.1-8b-instant';
            type CostMapKey = keyof typeof import('../config/costMap').COST_PER_1M_TOKENS;
            const { COST_PER_1M_TOKENS } = await import('../config/costMap');
            const groqCosts = COST_PER_1M_TOKENS[groqModelName as CostMapKey] || { input: 99, output: 99 };
            const isGroqFree = groqCosts.input === 0 && groqCosts.output === 0;

            let titleToSave: string;

            if (isGroqFree) {
              try {
                const titlePrompt = `Gere um t√≠tulo curto e conciso (m√°ximo 5 palavras) para esta conversa, baseado na primeira pergunta do usu√°rio. Responda APENAS com o t√≠tulo, sem introdu√ß√£o. Pergunta: "${message}"`;
                
                // --- O "TIMEOUT" (A "CORRIDA") ---
                const titleGeneration = aiService.chat(
                  [{ role: 'user', content: titlePrompt }],
                  'groq'
                );

                const timeout = createTimeout(5000, "Timeout: Gera√ß√£o de t√≠tulo demorou mais de 5s");

                const titleResponse = await Promise.race([
                  titleGeneration,
                  timeout
                ]) as AiServiceResponse;
                // --- FIM DO TIMEOUT ---

                titleToSave = titleResponse.response.replace(/"/g, '').trim();

              } catch (err: any) {
                console.warn("Falha ao gerar t√≠tulo (Timeout ou Erro de API):", err.message);
                titleToSave = `Conversa: ${message.substring(0, 20)}...`;
              }
            } else {
              console.warn("Gera√ß√£o de t√≠tulo desabilitada (Groq n√£o √© mais gr√°tis).");
              titleToSave = `Conversa: ${message.substring(0, 20)}...`;
            }

            try {
              if (titleToSave && titleToSave.length > 0) {
                await prisma.chat.update({
                  where: { id: currentChat.id },
                  data: { title: titleToSave }
                });
                logger.info(`T√≠tulo gerado para chat ${currentChat.id}: "${titleToSave}"`);
              }
            } catch (dbErr) {
              console.error("Falha ao salvar t√≠tulo:", dbErr);
            }
          })();
        }

      } catch (error: any) {
        if (watchdogTimer) clearTimeout(watchdogTimer);
        writeSSE({ type: 'debug', log: `üí• ERRO FATAL: ${error.message}` });
        console.error("Erro fatal no stream:", error);
        writeSSE({ type: 'error', error: error.message || 'Erro no servidor' });
      } finally {
        if (watchdogTimer) clearTimeout(watchdogTimer);
        writeSSE({ type: 'debug', log: 'üèÅ Encerrando conex√£o SSE' });
        res.end();
      }

    } catch (error) {
      // Se erro acontecer antes do streaming come√ßar
      if (!res.headersSent) {
        return next(error);
      } else {
        console.error("Erro ap√≥s headers SSE enviados:", error);
        res.end();
      }
    }
  },
};