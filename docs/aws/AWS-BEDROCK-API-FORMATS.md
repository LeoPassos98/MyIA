# AWS Bedrock - Formatos de API por Provedor

## üéØ Problema Resolvido

Diferentes modelos no AWS Bedrock usam formatos de API distintos. Enviar par√¢metros no formato errado resulta em erro:

```
[ERRO] Malformed input request: 
#: extraneous key [top_p] is not permitted
#: extraneous key [system] is not permitted
#: extraneous key [top_k] is not permitted
#: extraneous key [messages] is not permitted
#: extraneous key [anthropic_version] is not permitted
```

---

## üìã Provedores Suportados

### 1. **Anthropic Claude** (`anthropic.*`)

**Modelos:**
- `anthropic.claude-3-5-sonnet-20241022-v2:0`
- `anthropic.claude-3-5-haiku-20241022-v1:0`
- `anthropic.claude-haiku-4-5-20251001-v1:0`
- `anthropic.claude-sonnet-4-20250514-v1:0`

**Formato do Payload:**
```json
{
  "anthropic_version": "bedrock-2023-05-31",
  "max_tokens": 2048,
  "messages": [
    { "role": "user", "content": "Hello" },
    { "role": "assistant", "content": "Hi!" }
  ],
  "temperature": 0.7,
  "top_k": 250,
  "top_p": 0.999,
  "system": "You are a helpful assistant"
}
```

**Par√¢metros:**
- ‚úÖ `anthropic_version` - Vers√£o da API (obrigat√≥rio)
- ‚úÖ `messages` - Array de mensagens (obrigat√≥rio)
- ‚úÖ `system` - System prompt (opcional)
- ‚úÖ `max_tokens` - M√°ximo de tokens
- ‚úÖ `temperature` - Temperatura (0-1)
- ‚úÖ `top_k` - Top K sampling
- ‚úÖ `top_p` - Top P sampling

**Formato de Resposta (Stream):**
```json
{
  "type": "content_block_delta",
  "delta": { "text": "Hello" }
}
{
  "type": "message_stop"
}
```

---

### 2. **Cohere Command** (`cohere.*`)

**Modelos:**
- `cohere.command-r-v1:0`
- `cohere.command-r-plus-v1:0`
- `cohere.command-light-v14`
- `cohere.command-text-v14`

**Formato do Payload:**
```json
{
  "message": "What is the capital of France?",
  "chat_history": [
    { "role": "USER", "message": "Hello" },
    { "role": "CHATBOT", "message": "Hi there!" }
  ],
  "preamble": "You are a helpful assistant",
  "temperature": 0.7,
  "max_tokens": 2048,
  "p": 0.9
}
```

**Par√¢metros:**
- ‚úÖ `message` - Mensagem atual do usu√°rio (obrigat√≥rio)
- ‚úÖ `chat_history` - Hist√≥rico de conversa√ß√£o (opcional)
- ‚úÖ `preamble` - System prompt (opcional)
- ‚úÖ `max_tokens` - M√°ximo de tokens
- ‚úÖ `temperature` - Temperatura (0-1)
- ‚úÖ `p` - Top P sampling (equivalente a `top_p`)
- ‚ùå `stream` - **N√ÉO suportado** (streaming √© controlado pelo AWS Bedrock, n√£o pelo payload)
- ‚ùå `top_k` - N√£o suportado
- ‚ùå `anthropic_version` - N√£o suportado
- ‚ùå `messages` - N√£o suportado (usa `message` + `chat_history`)
- ‚ùå `system` - N√£o suportado (usa `preamble`)

**IMPORTANTE:** O streaming √© controlado pelo comando `InvokeModelWithResponseStreamCommand` do AWS SDK, n√£o pelo payload. N√£o adicione `stream: true` ao payload do Cohere.

**Formato de Resposta (Stream):**
```json
{
  "text": "Paris",
  "is_finished": false
}
{
  "text": " is the capital",
  "is_finished": false
}
{
  "is_finished": true
}
```

---

### 3. **Amazon Titan/Nova** (`amazon.*`)

**Modelos:**
- `amazon.titan-text-express-v1`
- `amazon.titan-text-lite-v1`
- `amazon.nova-2-lite-v1:0`
- `amazon.nova-2-micro-v1:0`
- `amazon.nova-2-pro-v1:0`

**Formato do Payload:**
```json
{
  "inputText": "System: You are helpful\n\nUser: Hello\n\nAssistant: Hi!",
  "textGenerationConfig": {
    "maxTokenCount": 2048,
    "temperature": 0.7,
    "topP": 0.9
  }
}
```

**Par√¢metros:**
- ‚úÖ `inputText` - Texto formatado com roles (obrigat√≥rio)
- ‚úÖ `textGenerationConfig.maxTokenCount` - M√°ximo de tokens
- ‚úÖ `textGenerationConfig.temperature` - Temperatura (0-1)
- ‚úÖ `textGenerationConfig.topP` - Top P sampling
- ‚ùå `messages` - N√£o suportado (usa `inputText`)
- ‚ùå `anthropic_version` - N√£o suportado
- ‚ùå `top_k` - N√£o suportado

**Formato de Resposta (Stream):**
```json
{
  "outputText": "Hello",
  "completionReason": null
}
{
  "outputText": " there",
  "completionReason": "FINISH"
}
```

---

## üîß Implementa√ß√£o

### Detec√ß√£o Autom√°tica de Provedor

O sistema detecta automaticamente o provedor baseado no prefixo do `modelId`:

```typescript
function detectModelProvider(modelId: string): ModelProvider {
  const prefix = modelId.split('.')[0].toLowerCase();
  
  switch (prefix) {
    case 'anthropic': return ModelProvider.ANTHROPIC;
    case 'cohere': return ModelProvider.COHERE;
    case 'amazon': return ModelProvider.AMAZON;
    case 'ai21': return ModelProvider.AI21;
    case 'meta': return ModelProvider.META;
    case 'mistral': return ModelProvider.MISTRAL;
    default: return ModelProvider.ANTHROPIC; // Fallback
  }
}
```

### Cria√ß√£o de Payload Espec√≠fico

```typescript
function createPayloadForProvider(
  provider: ModelProvider,
  messages: any[],
  options: AIRequestOptions
): any {
  switch (provider) {
    case ModelProvider.ANTHROPIC:
      return createAnthropicPayload(messages, options);
    
    case ModelProvider.COHERE:
      return createCoherePayload(messages, options);
    
    case ModelProvider.AMAZON:
      return createAmazonPayload(messages, options);
    
    default:
      return createAnthropicPayload(messages, options);
  }
}
```

### Processamento de Chunks

Cada provedor retorna chunks em formato diferente:

```typescript
function* processChunkForProvider(
  provider: ModelProvider,
  chunk: any
): Generator<StreamChunk> {
  switch (provider) {
    case ModelProvider.ANTHROPIC:
      if (chunk.type === 'content_block_delta' && chunk.delta?.text) {
        yield { type: 'chunk', content: chunk.delta.text };
      }
      break;
    
    case ModelProvider.COHERE:
      if (chunk.text) {
        yield { type: 'chunk', content: chunk.text };
      }
      break;
    
    case ModelProvider.AMAZON:
      if (chunk.outputText) {
        yield { type: 'chunk', content: chunk.outputText };
      }
      break;
  }
}
```

---

## ‚ùì Perguntas Frequentes

### 1. **Preciso sempre enviar todos os par√¢metros?**

**N√£o.** Cada provedor tem seus par√¢metros obrigat√≥rios e opcionais:

- **Anthropic**: Obrigat√≥rio apenas `messages` e `max_tokens`
- **Cohere**: Obrigat√≥rio apenas `message` e `stream`
- **Amazon**: Obrigat√≥rio apenas `inputText`

Par√¢metros como `temperature`, `top_p`, `system` s√£o sempre opcionais.

### 2. **Posso n√£o enviar nenhum par√¢metro opcional?**

**Sim.** O sistema usa valores padr√£o:
- `temperature`: 0.7
- `max_tokens`: 2048
- `top_p`: 0.9 ou 0.999 (dependendo do provedor)

### 3. **Como saber qual formato usar para cada modelo?**

O sistema **detecta automaticamente** baseado no prefixo do `modelId`:

| Prefixo | Provedor | Formato |
|---------|----------|---------|
| `anthropic.*` | Anthropic | Claude API |
| `cohere.*` | Cohere | Cohere API |
| `amazon.*` | Amazon | Titan/Nova API |
| `ai21.*` | AI21 | AI21 API (TODO) |
| `meta.*` | Meta | Llama API (TODO) |
| `mistral.*` | Mistral | Mistral API (TODO) |

### 4. **O que acontece se eu enviar par√¢metros errados?**

O AWS Bedrock retorna erro `400 Bad Request` com mensagem:
```
Malformed input request: extraneous key [parameter_name] is not permitted
```

Com a implementa√ß√£o atual, isso **n√£o acontece mais** porque o sistema envia apenas os par√¢metros corretos para cada provedor.

### 5. **Todos os modelos Cohere t√™m o mesmo problema?**

**Sim.** Todos os modelos Cohere (`cohere.*`) usam a API Cohere, que √© diferente da API Anthropic. O mesmo vale para outros provedores.

---

## üß™ Testando

### Teste com Cohere Command R

```bash
curl -X POST http://localhost:3001/api/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "message": "Hello, how are you?",
    "provider": "bedrock",
    "modelId": "cohere.command-r-v1:0",
    "apiKey": "ACCESS_KEY:SECRET_KEY"
  }'
```

### Teste com Anthropic Claude

```bash
curl -X POST http://localhost:3001/api/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "message": "Hello, how are you?",
    "provider": "bedrock",
    "modelId": "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "apiKey": "ACCESS_KEY:SECRET_KEY"
  }'
```

### Teste com Amazon Nova

```bash
curl -X POST http://localhost:3001/api/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "message": "Hello, how are you?",
    "provider": "bedrock",
    "modelId": "amazon.nova-2-lite-v1:0",
    "apiKey": "ACCESS_KEY:SECRET_KEY"
  }'
```

---

## üìö Refer√™ncias

- [AWS Bedrock API Reference](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html)
- [Anthropic Claude on Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html)
- [Cohere Command on Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-cohere-command-r-plus.html)
- [Amazon Titan on Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-text.html)

---

## ‚úÖ Status

- ‚úÖ **Anthropic Claude** - Implementado e testado
- ‚úÖ **Cohere Command** - Implementado (aguardando teste)
- ‚úÖ **Amazon Titan/Nova** - Implementado (aguardando teste)
- ‚è≥ **AI21 Jurassic** - Pendente
- ‚è≥ **Meta Llama** - Pendente
- ‚è≥ **Mistral** - Pendente
- ‚è≥ **Stability AI** - Pendente

---

**Documento criado em**: 2026-01-16  
**Vers√£o**: 1.0  
**Autor**: Sistema MyIA
