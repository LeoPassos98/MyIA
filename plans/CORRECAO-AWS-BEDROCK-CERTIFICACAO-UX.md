# Corre√ß√£o AWS Bedrock: Certifica√ß√£o vs Uso Real + UX

**Data:** 2026-01-27  
**Autor:** Debug Mode  
**Status:** üî¥ CR√çTICO - Requer A√ß√£o Imediata

---

## üìã Sum√°rio Executivo

### Problema Cr√≠tico Identificado

Modelos AWS Bedrock s√£o **certificados com sucesso** mas **falham ao serem usados no chat**, exibindo mensagens de erro t√©cnicas e confusas para o usu√°rio:

```
[ERRO] Falha ao invocar modelo anthropic.claude-haiku-4-5-20251001-v1:0. 
Tentativas: 3 varia√ß√µes. 
Erro: Invocation of model ID anthropic.claude-haiku-4-5-20251001-v1:0 with on-demand throughput isn't supported. 
Retry your request with the ID or ARN of an inference profile that contains this model.
```

**Observa√ß√£o cr√≠tica do usu√°rio:**  
> "mesmo que o modelo seja validado pelo nosso validador, o que prova que tem algo errado em algum lugar"

### Causa Raiz Identificada

**‚ùå DISCREP√ÇNCIA ENTRE CERTIFICA√á√ÉO E USO REAL:**

1. **Sistema de Certifica√ß√£o** ([`certification.service.ts`](backend/src/services/ai/certification/certification.service.ts:1)):
   - Usa [`BedrockProvider.streamChat()`](backend/src/services/ai/providers/bedrock.ts:138) diretamente
   - O provider tem **auto-test com 3 varia√ß√µes** de model ID (linhas 203-210)
   - Tenta: `modelId` ‚Üí `inferenceProfile` ‚Üí `modelId sem "2"`
   - **Sucesso em qualquer varia√ß√£o = modelo certificado** ‚úÖ

2. **Sistema de Chat Real** (uso pelo usu√°rio):
   - Tamb√©m usa [`BedrockProvider.streamChat()`](backend/src/services/ai/providers/bedrock.ts:138)
   - **MESMA L√ìGICA** de auto-test com 3 varia√ß√µes
   - **Deveria funcionar identicamente** ü§î

3. **Fun√ß√£o `getInferenceProfileId()`** ([`bedrock.ts:43`](backend/src/services/ai/providers/bedrock.ts:43)):
   - Verifica se modelo requer inference profile via registry
   - Converte `anthropic.claude-haiku-4-5-20251001-v1:0` ‚Üí `us.anthropic.claude-haiku-4-5-20251001-v1:0`
   - **√â usada tanto na certifica√ß√£o quanto no chat** ‚úÖ

### Hip√≥teses da Causa Raiz

#### üéØ Hip√≥tese #1: Erro de Throughput/Provisionamento (MAIS PROV√ÅVEL)

**Evid√™ncia:**
```
Invocation of model ID anthropic.claude-haiku-4-5-20251001-v1:0 with on-demand throughput isn't supported.
```

**An√°lise:**
- Erro menciona **"on-demand throughput"** - indica que modelo requer **provisionamento pr√©vio**
- Alguns modelos AWS Bedrock requerem:
  - **Provisioned Throughput** (capacidade reservada)
  - **Cross-Region Inference** (inference profile obrigat√≥rio)
  - **Model Access Request** (aprova√ß√£o manual da AWS)

**Problema:**
- [`error-categorizer.ts`](backend/src/services/ai/certification/error-categorizer.ts:84) detecta "requires inference profile" como `CONFIGURATION_ERROR`
- Mas **N√ÉO detecta "on-demand throughput"** como erro espec√≠fico
- Sistema tenta inference profile mas modelo pode estar **desabilitado na conta AWS**

#### üéØ Hip√≥tese #2: Timing/Estado da Conta AWS

**Evid√™ncia:**
- Certifica√ß√£o pode ter sido feita quando modelo estava dispon√≠vel
- Uso posterior falha porque:
  - Modelo foi desabilitado na conta AWS
  - Quota foi excedida
  - Regi√£o mudou

**Problema:**
- Cache de certifica√ß√£o dura **7 dias** (linha 354 de [`certification.service.ts`](backend/src/services/ai/certification/certification.service.ts:354))
- Estado real do modelo pode ter mudado

#### üéØ Hip√≥tese #3: Diferen√ßa Sutil na Invoca√ß√£o

**Evid√™ncia:**
- Certifica√ß√£o e chat usam mesma fun√ß√£o [`streamChat()`](backend/src/services/ai/providers/bedrock.ts:138)
- Mas podem passar **par√¢metros diferentes** (temperature, maxTokens, etc)

**Problema:**
- Alguns modelos podem aceitar invoca√ß√£o simples mas rejeitar com certos par√¢metros
- Certifica√ß√£o usa par√¢metros m√≠nimos, chat usa par√¢metros completos

---

## üîç An√°lise T√©cnica Detalhada

### A. Sistema de Certifica√ß√£o

**Arquivo:** [`backend/src/services/ai/certification/certification.service.ts`](backend/src/services/ai/certification/certification.service.ts:1)

**Fluxo de Certifica√ß√£o:**

```typescript
// 1. Obter metadata do modelo (linha 154)
const metadata = ModelRegistry.getModel(modelId);
// ‚úÖ anthropic.claude-haiku-4-5-20251001-v1:0 existe no registry

// 2. Criar BedrockProvider (linha 166)
const provider = new BedrockProvider(credentials.region);

// 3. Executar testes (linha 186)
const runner = new TestRunner(provider, apiKey);
const testResults = await runner.runTests(modelId, tests);
```

**Testes Executados:**

1. **Base Tests** ([`base.spec.ts`](backend/src/services/ai/certification/test-specs/base.spec.ts:1)):
   - `basic-prompt`: "Hi" ‚Üí espera resposta
   - `streaming-test`: "Count from 1 to 5" ‚Üí valida chunks
   - `parameter-validation`: temperatura + maxTokens
   - `error-handling`: prompt vazio

2. **Anthropic Tests** ([`anthropic.spec.ts`](backend/src/services/ai/certification/test-specs/anthropic.spec.ts:1)):
   - `anthropic-system-message`: valida system messages
   - `anthropic-temperature-top-p-conflict`: valida ambos par√¢metros

**Cada teste chama:**
```typescript
// linha 23 de base.spec.ts
for await (const chunk of provider.streamChat(messages, { modelId, apiKey })) {
  // Processa chunks
}
```

**Problema Identificado:**
- ‚úÖ Testes usam `streamChat()` corretamente
- ‚úÖ Auto-test de 3 varia√ß√µes √© executado
- ‚ùå **MAS**: Se modelo requer provisionamento, erro pode ser intermitente
- ‚ùå **MAS**: Testes n√£o validam se modelo est√° realmente dispon√≠vel para uso cont√≠nuo

### B. Sistema de Invoca√ß√£o (Chat Real)

**Arquivo:** [`backend/src/services/ai/providers/bedrock.ts`](backend/src/services/ai/providers/bedrock.ts:1)

**Fluxo de Invoca√ß√£o:**

```typescript
// linha 138: streamChat()
async *streamChat(messages: any[], options: AIRequestOptions) {
  // 1. Validar credenciais (linha 143-150)
  const [accessKeyId, secretAccessKey] = options.apiKey.split(':');
  
  // 2. Criar cliente Bedrock (linha 152)
  const client = new BedrockRuntimeClient({
    region: this.region,
    credentials: { accessKeyId, secretAccessKey }
  });
  
  // 3. Obter adapter (linha 160)
  adapter = AdapterFactory.getAdapterForModel(options.modelId);
  
  // 4. Formatar request (linha 185)
  const { body, contentType, accept } = adapter.formatRequest(
    universalMessages,
    universalOptions
  );
  
  // 5. Normalizar model ID (linha 192)
  const normalizedModelId = normalizeModelId(originalModelId);
  
  // 6. Obter inference profile (linha 200)
  const modelIdWithProfile = getInferenceProfileId(normalizedModelId, this.region);
  
  // 7. AUTO-TEST: 3 varia√ß√µes (linha 203-210)
  const modelIdVariations = [
    normalizedModelId,           // Varia√ß√£o 1: sem sufixo
    modelIdWithProfile,          // Varia√ß√£o 2: com inference profile
    normalizedModelId.replace('nova-2-', 'nova-'),  // Varia√ß√£o 3: sem "2"
  ];
  
  // 8. Tentar cada varia√ß√£o com retry (linha 217-296)
  for (const testModelId of modelIdVariations) {
    for (let attempt = 0; attempt <= this.retryConfig.maxRetries; attempt++) {
      try {
        const command = new InvokeModelWithResponseStreamCommand({
          modelId: testModelId,
          contentType,
          accept,
          body: JSON.stringify(body)
        });
        
        const response = await client.send(command);
        // ‚úÖ Sucesso - processa stream
        
      } catch (error) {
        // ‚ùå Falha - tenta pr√≥xima varia√ß√£o ou retry
      }
    }
  }
  
  // 9. Se todas falharam (linha 299-304)
  yield {
    type: 'error',
    error: `Falha ao invocar modelo ${originalModelId}. 
            Tentativas: ${modelIdVariations.length} varia√ß√µes. 
            Erro: ${errorMessage}`
  };
}
```

**Fun√ß√£o `getInferenceProfileId()`** (linha 43):

```typescript
function getInferenceProfileId(modelId: string, region: string): string {
  const baseModelId = normalizeModelId(modelId);
  
  // Se j√° tem prefixo de regi√£o, retornar
  if (baseModelId.startsWith('us.') || baseModelId.startsWith('eu.')) {
    return baseModelId;
  }
  
  // Verificar se modelo requer inference profile via registry
  const platformRule = ModelRegistry.getPlatformRules(baseModelId, 'bedrock');
  
  if (platformRule?.rule === 'requires_inference_profile') {
    // Usar system-defined inference profile
    const regionPrefix = region.split('-')[0]; // 'us' de 'us-east-1'
    const inferenceProfileId = `${regionPrefix}.${baseModelId}`;
    logger.info(`üîÑ [Bedrock] Using Inference Profile: ${inferenceProfileId}`);
    return inferenceProfileId;
  }
  
  return baseModelId;
}
```

**An√°lise:**
- ‚úÖ L√≥gica id√™ntica entre certifica√ß√£o e chat
- ‚úÖ Inference profile √© aplicado corretamente
- ‚úÖ Auto-test tenta 3 varia√ß√µes
- ‚ùå **MAS**: Erro "on-demand throughput" indica que **NENHUMA varia√ß√£o funciona**

### C. Registry e Platform Rules

**Arquivo:** [`backend/src/services/ai/registry/models/anthropic.models.ts`](backend/src/services/ai/registry/models/anthropic.models.ts:1)

**Modelo em quest√£o** (linha 72-101):

```typescript
{
  modelId: 'anthropic.claude-haiku-4-5-20251001-v1:0',
  vendor: 'anthropic',
  displayName: 'Claude 4.5 Haiku',
  description: 'Next-gen Haiku with improved performance',
  capabilities: {
    streaming: true,
    vision: true,
    functionCalling: true,
    maxContextWindow: 200000,
    maxOutputTokens: 8192,
  },
  supportedPlatforms: ['bedrock'],
  platformRules: [
    {
      platform: 'bedrock',
      rule: 'requires_inference_profile',  // ‚úÖ Regra presente
      config: {
        profileFormat: '{region}.{modelId}',
      },
    },
  ],
  adapterClass: 'AnthropicAdapter',
}
```

**An√°lise:**
- ‚úÖ Modelo tem regra `requires_inference_profile`
- ‚úÖ `getInferenceProfileId()` detecta e aplica
- ‚úÖ Converte para `us.anthropic.claude-haiku-4-5-20251001-v1:0`
- ‚ùå **MAS**: Erro indica que **inference profile tamb√©m falha**

### D. Categoriza√ß√£o de Erros

**Arquivo:** [`backend/src/services/ai/certification/error-categorizer.ts`](backend/src/services/ai/certification/error-categorizer.ts:1)

**Detec√ß√£o de "on-demand throughput"** (linha 82-94):

```typescript
// CONFIGURATION_ERROR - Problema de configura√ß√£o
else if (
  /requires.*inference profile/i.test(errorLower) ||
  /inference profile.*required/i.test(errorLower) ||
  /region.*not supported/i.test(errorLower) ||
  /invalid region/i.test(errorLower) ||
  /configuration.*invalid/i.test(errorLower) ||
  /ValidationException/i.test(errorMessage) ||
  /InvalidParameterException/i.test(errorMessage) ||
  /model.*requires.*cross-region/i.test(errorLower)
) {
  category = ErrorCategory.CONFIGURATION_ERROR;
}
```

**Problema Identificado:**
- ‚ùå **N√ÉO detecta "on-demand throughput"**
- ‚ùå **N√ÉO detecta "provisioned throughput"**
- ‚ùå Erro cai em `UNKNOWN_ERROR` ou `UNAVAILABLE`

**Mensagem gerada** (linha 257-278):

```typescript
function createUserFriendlyMessage(category: ErrorCategory, originalError: string): string {
  const messageMap: Record<ErrorCategory, string> = {
    [ErrorCategory.UNAVAILABLE]: 'Modelo n√£o est√° dispon√≠vel',
    [ErrorCategory.UNKNOWN_ERROR]: 'Erro desconhecido'
  };
  
  return messageMap[category];
}
```

**Problema:**
- ‚ùå Mensagem gen√©rica demais
- ‚ùå N√£o explica o que fazer
- ‚ùå N√£o oferece alternativas

---

## üéØ Causa Raiz Confirmada

### Conclus√£o da An√°lise

**O problema N√ÉO √© discrep√¢ncia entre certifica√ß√£o e chat.**  
Ambos usam a mesma l√≥gica e deveriam ter o mesmo comportamento.

**O problema REAL √©:**

1. **Modelo requer provisionamento pr√©vio na conta AWS**
   - N√£o basta ter inference profile
   - Precisa de "Provisioned Throughput" ou "Model Access Request"
   - Erro "on-demand throughput isn't supported" confirma isso

2. **Sistema n√£o detecta este tipo de erro especificamente**
   - Categoriza√ß√£o n√£o reconhece "throughput" como erro
   - Cai em categoria gen√©rica

3. **Mensagens de erro s√£o t√©cnicas demais**
   - Usu√°rio v√™ erro AWS bruto
   - N√£o sabe o que fazer
   - N√£o tem alternativas

4. **Certifica√ß√£o pode passar por timing/sorte**
   - Se modelo estava dispon√≠vel temporariamente
   - Se quota n√£o estava excedida
   - Se regi√£o tinha capacidade

---

## üí° Proposta de Corre√ß√£o

### Princ√≠pios da Solu√ß√£o

1. ‚úÖ **N√£o criar Provider Pattern Gen√©rico** (decis√£o do usu√°rio)
2. ‚úÖ **Focar em corre√ß√µes pontuais** (n√£o features novas)
3. ‚úÖ **Priorizar UX** (mensagens claras e acion√°veis)
4. ‚úÖ **Melhorar confiabilidade** (detectar problemas reais)

### Corre√ß√µes Propostas

---

## üìù Corre√ß√£o #1: Detectar Erros de Throughput/Provisionamento

**Arquivo:** [`backend/src/services/ai/certification/error-categorizer.ts`](backend/src/services/ai/certification/error-categorizer.ts:82)

**Problema:**
- Erro "on-demand throughput isn't supported" n√£o √© detectado
- Cai em categoria gen√©rica

**Solu√ß√£o:**

```typescript
// PROVISIONING_REQUIRED - Modelo requer provisionamento pr√©vio
else if (
  /on-demand throughput.*not supported/i.test(errorLower) ||
  /provisioned throughput.*required/i.test(errorLower) ||
  /model.*requires.*provisioning/i.test(errorLower) ||
  /throughput.*not.*available/i.test(errorLower) ||
  /model access.*required/i.test(errorLower) ||
  /request.*id or arn.*inference profile/i.test(errorLower)
) {
  category = ErrorCategory.PROVISIONING_REQUIRED;
}
```

**Adicionar nova categoria:**

```typescript
// backend/src/services/ai/certification/types.ts
export enum ErrorCategory {
  UNAVAILABLE = 'UNAVAILABLE',
  PERMISSION_ERROR = 'PERMISSION_ERROR',
  AUTHENTICATION_ERROR = 'AUTHENTICATION_ERROR',
  RATE_LIMIT = 'RATE_LIMIT',
  TIMEOUT = 'TIMEOUT',
  CONFIGURATION_ERROR = 'CONFIGURATION_ERROR',
  PROVISIONING_REQUIRED = 'PROVISIONING_REQUIRED',  // ‚úÖ NOVO
  QUALITY_ISSUE = 'QUALITY_ISSUE',
  NETWORK_ERROR = 'NETWORK_ERROR',
  UNKNOWN_ERROR = 'UNKNOWN_ERROR'
}
```

**Severidade e a√ß√µes:**

```typescript
// Severidade
[ErrorCategory.PROVISIONING_REQUIRED]: ErrorSeverity.CRITICAL,

// A√ß√µes sugeridas
[ErrorCategory.PROVISIONING_REQUIRED]: [
  'üîß Modelo requer provisionamento pr√©vio na AWS',
  'üìã Acesse AWS Console ‚Üí Bedrock ‚Üí Model Access',
  '‚úÖ Solicite acesso ao modelo (pode levar minutos/horas)',
  'üí° Ou use modelo alternativo que n√£o requer provisionamento',
  'üìö Documenta√ß√£o: https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html'
],

// Mensagem amig√°vel
[ErrorCategory.PROVISIONING_REQUIRED]: 'Modelo requer habilita√ß√£o pr√©via na conta AWS',
```

**Impacto:**
- ‚úÖ Detecta erro espec√≠fico de throughput
- ‚úÖ Categoriza como `CRITICAL` (modelo n√£o pode ser usado)
- ‚úÖ Oferece a√ß√µes claras e acion√°veis
- ‚úÖ Direciona para documenta√ß√£o AWS

---

## üìù Corre√ß√£o #2: Melhorar Mensagens de Erro no Chat

**Arquivo:** [`backend/src/services/ai/providers/bedrock.ts`](backend/src/services/ai/providers/bedrock.ts:299)

**Problema:**
- Mensagem atual √© t√©cnica demais:
  ```
  Falha ao invocar modelo anthropic.claude-haiku-4-5-20251001-v1:0. 
  Tentativas: 3 varia√ß√µes. 
  Erro: Invocation of model ID anthropic.claude-haiku-4-5-20251001-v1:0 with on-demand throughput isn't supported.
  ```

**Solu√ß√£o:**

```typescript
// Se chegou aqui, todas as varia√ß√µes falharam
const errorMessage = lastGlobalError instanceof Error ? lastGlobalError.message : 'Erro desconhecido no AWS Bedrock';

// ‚úÖ NOVO: Categorizar erro para mensagem amig√°vel
const categorizedError = categorizeError(errorMessage);

// ‚úÖ NOVO: Criar mensagem amig√°vel
let userFriendlyMessage = '';

if (categorizedError.category === ErrorCategory.PROVISIONING_REQUIRED) {
  userFriendlyMessage = `
‚ùå Modelo indispon√≠vel: ${originalModelId}

Este modelo requer habilita√ß√£o pr√©via na sua conta AWS.

üîß Como resolver:
1. Acesse AWS Console ‚Üí Bedrock ‚Üí Model Access
2. Solicite acesso ao modelo "${originalModelId}"
3. Aguarde aprova√ß√£o (pode levar minutos ou horas)

üí° Alternativas:
‚Ä¢ Tente Claude 3.5 Sonnet (anthropic.claude-3-5-sonnet-20241022-v2:0)
‚Ä¢ Tente Claude 3 Haiku (anthropic.claude-3-haiku-20240307-v1:0)

üìö Documenta√ß√£o: https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html
  `.trim();
} else if (categorizedError.category === ErrorCategory.PERMISSION_ERROR) {
  userFriendlyMessage = `
‚ùå Sem permiss√£o para usar o modelo

Sua conta AWS n√£o tem permiss√£o para invocar este modelo.

üîß Como resolver:
1. Adicione pol√≠tica IAM: bedrock:InvokeModel
2. Adicione pol√≠tica IAM: bedrock:InvokeModelWithResponseStream
3. Verifique se a regi√£o ${this.region} est√° permitida

üìö Documenta√ß√£o: https://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html
  `.trim();
} else if (categorizedError.category === ErrorCategory.UNAVAILABLE) {
  userFriendlyMessage = `
‚ùå Modelo n√£o dispon√≠vel: ${originalModelId}

Este modelo n√£o est√° dispon√≠vel na regi√£o ${this.region}.

üîß Poss√≠veis causas:
‚Ä¢ Modelo n√£o existe nesta regi√£o
‚Ä¢ Modelo foi descontinuado
‚Ä¢ Nome do modelo est√° incorreto

üí° Alternativas:
‚Ä¢ Verifique modelos dispon√≠veis na sua regi√£o
‚Ä¢ Tente outra regi√£o AWS
‚Ä¢ Use modelo similar dispon√≠vel

üìö Documenta√ß√£o: https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html
  `.trim();
} else {
  // Erro gen√©rico - manter mensagem t√©cnica mas melhorada
  userFriendlyMessage = `
‚ùå Erro ao invocar modelo: ${originalModelId}

Tentativas realizadas: ${modelIdVariations.length} varia√ß√µes
Regi√£o: ${this.region}

Erro t√©cnico:
${errorMessage}

üí° Sugest√µes:
‚Ä¢ Verifique se o modelo est√° dispon√≠vel na sua regi√£o
‚Ä¢ Confirme que suas credenciais AWS est√£o corretas
‚Ä¢ Tente novamente em alguns minutos

üìö Se o problema persistir, consulte os logs ou entre em contato com suporte.
  `.trim();
}

logger.error(`‚ùå [Bedrock Auto-Test] All ${modelIdVariations.length} variations failed for: ${originalModelId}`);
logger.error(`[Bedrock] Error category: ${categorizedError.category}`);
logger.error(`[Bedrock] User-friendly message prepared`);

yield {
  type: 'error',
  error: userFriendlyMessage
};
```

**Impacto:**
- ‚úÖ Mensagens claras e amig√°veis
- ‚úÖ Explica o problema em portugu√™s
- ‚úÖ Oferece passos acion√°veis
- ‚úÖ Sugere alternativas
- ‚úÖ Links para documenta√ß√£o
- ‚úÖ Mant√©m erro t√©cnico nos logs

---

## üìù Corre√ß√£o #3: Validar Disponibilidade Real na Certifica√ß√£o

**Arquivo:** [`backend/src/services/ai/certification/certification.service.ts`](backend/src/services/ai/certification/certification.service.ts:220)

**Problema:**
- Certifica√ß√£o pode passar por timing/sorte
- N√£o valida se modelo est√° realmente dispon√≠vel para uso cont√≠nuo

**Solu√ß√£o:**

```typescript
// 6. Categorizar erros e determinar status
let categorizedError: CategorizedError | undefined;
let overallSeverity: ErrorSeverity | undefined;
let isAvailable = true;
let status: ModelCertificationStatus;
let isCertified = false;

// ... c√≥digo existente ...

// ‚úÖ NOVO: Verificar se h√° erros de provisionamento
if (categorizedError) {
  if (categorizedError.category === ErrorCategory.PROVISIONING_REQUIRED) {
    // Modelo requer provisionamento - marcar como FAILED mesmo com successRate alto
    status = ModelCertificationStatus.FAILED;
    isAvailable = false;
    isCertified = false;
    logger.info(`[CertificationService] ‚ùå Modelo ${modelId} marcado como FAILED devido a PROVISIONING_REQUIRED`);
    
    // ‚úÖ NOVO: Adicionar nota explicativa
    qualityIssues.push('‚ö†Ô∏è Modelo requer habilita√ß√£o pr√©via na conta AWS (Provisioned Throughput)');
  }
  else if (
    categorizedError.category === ErrorCategory.UNAVAILABLE ||
    categorizedError.category === ErrorCategory.PERMISSION_ERROR ||
    categorizedError.category === ErrorCategory.AUTHENTICATION_ERROR ||
    categorizedError.category === ErrorCategory.CONFIGURATION_ERROR
  ) {
    // ... c√≥digo existente ...
  }
}
```

**Impacto:**
- ‚úÖ Detecta modelos que requerem provisionamento
- ‚úÖ Marca como `FAILED` mesmo se alguns testes passarem
- ‚úÖ Adiciona nota explicativa no `qualityIssues`
- ‚úÖ Evita certificar modelos que n√£o funcionar√£o no chat

---

## üìù Corre√ß√£o #4: Adicionar Teste de Disponibilidade Real

**Arquivo:** [`backend/src/services/ai/certification/test-specs/base.spec.ts`](backend/src/services/ai/certification/test-specs/base.spec.ts:246)

**Problema:**
- Testes atuais validam funcionalidade mas n√£o disponibilidade real
- Modelo pode passar em testes mas n√£o estar dispon√≠vel para uso

**Solu√ß√£o:**

```typescript
// ‚úÖ NOVO TESTE: Validar disponibilidade real do modelo
{
  id: 'availability-check',
  name: 'Model Availability Check',
  description: 'Valida se modelo est√° realmente dispon√≠vel para uso (n√£o apenas funcional)',
  timeout: 30000,
  
  async run(modelId: string, provider: any, apiKey: string): Promise<TestResult> {
    const startTime = Date.now();
    
    try {
      // Fazer 2 invoca√ß√µes consecutivas para garantir disponibilidade consistente
      const messages = [{ role: 'user', content: 'Test' }];
      
      // Primeira invoca√ß√£o
      let firstSuccess = false;
      for await (const chunk of provider.streamChat(messages, { modelId, apiKey })) {
        if (chunk.type === 'chunk' && chunk.content) {
          firstSuccess = true;
          break;
        }
        if (chunk.type === 'error') {
          // Verificar se √© erro de provisionamento
          if (
            chunk.error.includes('on-demand throughput') ||
            chunk.error.includes('provisioned throughput') ||
            chunk.error.includes('model access')
          ) {
            return {
              testId: 'availability-check',
              testName: 'Model Availability Check',
              passed: false,
              error: 'Model requires provisioning or access request in AWS account',
              latencyMs: Date.now() - startTime,
              metadata: {
                errorType: 'provisioning_required',
                userAction: 'Enable model in AWS Console ‚Üí Bedrock ‚Üí Model Access'
              }
            };
          }
          
          return {
            testId: 'availability-check',
            testName: 'Model Availability Check',
            passed: false,
            error: chunk.error,
            latencyMs: Date.now() - startTime
          };
        }
      }
      
      if (!firstSuccess) {
        return {
          testId: 'availability-check',
          testName: 'Model Availability Check',
          passed: false,
          error: 'No response from model',
          latencyMs: Date.now() - startTime
        };
      }
      
      // Segunda invoca√ß√£o (validar consist√™ncia)
      await new Promise(resolve => setTimeout(resolve, 1000)); // 1s delay
      
      let secondSuccess = false;
      for await (const chunk of provider.streamChat(messages, { modelId, apiKey })) {
        if (chunk.type === 'chunk' && chunk.content) {
          secondSuccess = true;
          break;
        }
      }
      
      const latency = Date.now() - startTime;
      
      if (!secondSuccess) {
        return {
          testId: 'availability-check',
          testName: 'Model Availability Check',
          passed: false,
          error: 'Model available but inconsistent (first call succeeded, second failed)',
          latencyMs: latency,
          metadata: {
            warning: 'Model may have intermittent availability issues'
          }
        };
      }
      
      return {
        testId: 'availability-check',
        testName: 'Model Availability Check',
        passed: true,
        latencyMs: latency,
        metadata: {
          consecutiveSuccesses: 2
        }
      };
      
    } catch (error: any) {
      return {
        testId: 'availability-check',
        testName: 'Model Availability Check',
        passed: false,
        error: error.message,
        latencyMs: Date.now() - startTime
      };
    }
  }
}
```

**Impacto:**
- ‚úÖ Valida disponibilidade real com 2 invoca√ß√µes consecutivas
- ‚úÖ Detecta erros de provisionamento especificamente
- ‚úÖ Adiciona metadata explicativa
- ‚úÖ Evita falsos positivos na certifica√ß√£o

---

## üìù Corre√ß√£o #5: Melhorar Logging de Discrep√¢ncias

**Arquivo:** [`backend/src/services/ai/providers/bedrock.ts`](backend/src/services/ai/providers/bedrock.ts:217)

**Problema:**
- Dif√≠cil debugar quando certifica√ß√£o passa mas chat falha
- Logs n√£o mostram diferen√ßas entre invoca√ß√µes

**Solu√ß√£o:**

```typescript
// Retry loop com backoff exponencial para esta varia√ß√£o
for (let attempt = 0; attempt <= this.retryConfig.maxRetries; attempt++) {
  try {
    // ‚úÖ NOVO: Log detalhado da tentativa
    logger.info(`[Bedrock] Attempting invocation:`, {
      modelId: testModelId,
      originalModelId,
      region: this.region,
      attempt: attempt + 1,
      maxRetries: this.retryConfig.maxRetries + 1,
      hasInferenceProfile: testModelId.startsWith('us.') || testModelId.startsWith('eu.'),
      requestBody: {
        temperature: universalOptions.temperature,
        maxTokens: universalOptions.maxTokens,
        topP: universalOptions.topP,
        topK: universalOptions.topK
      }
    });
    
    const command = new InvokeModelWithResponseStreamCommand({
      modelId: testModelId,
      contentType,
      accept,
      body: JSON.stringify(body)
    });
    
    const response = await client.send(command);
    
    // ‚úÖ NOVO: Log de sucesso
    logger.info(`‚úÖ [Bedrock] Invocation successful:`, {
      modelId: testModelId,
      attempt: attempt + 1,
      hadInferenceProfile: testModelId !== originalModelId
    });
    
    // ... resto do c√≥digo de processamento de stream ...
    
  } catch (error: unknown) {
    lastGlobalError = error;
    
    // ‚úÖ NOVO: Log detalhado do erro
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error(`‚ùå [Bedrock] Invocation failed:`, {
      modelId: testModelId,
      originalModelId,
      attempt: attempt + 1,
      errorMessage: errorMessage.substring(0, 200),
      errorType: error instanceof Error ? error.constructor.name : 'Unknown'
    });
    
    // ... resto do c√≥digo de retry ...
  }
}
```

**Impacto:**
- ‚úÖ Logs detalhados de cada tentativa
- ‚úÖ Mostra diferen√ßas entre certifica√ß√£o e chat
- ‚úÖ Facilita debug de problemas intermitentes
- ‚úÖ Identifica qual varia√ß√£o funcionou

---

## üìä Plano de Implementa√ß√£o

### Ordem de Prioridade

#### üî¥ **PRIORIDADE ALTA** (Implementar Primeiro)

1. **Corre√ß√£o #1: Detectar Erros de Throughput/Provisionamento**
   - **Arquivos:** 
     - [`backend/src/services/ai/certification/types.ts`](backend/src/services/ai/certification/types.ts:1)
     - [`backend/src/services/ai/certification/error-categorizer.ts`](backend/src/services/ai/certification/error-categorizer.ts:1)
   - **Estimativa:** 1-2 horas
   - **Justificativa:** Resolve o problema de categoriza√ß√£o incorreta

2. **Corre√ß√£o #2: Melhorar Mensagens de Erro no Chat**
   - **Arquivos:**
     - [`backend/src/services/ai/providers/bedrock.ts`](backend/src/services/ai/providers/bedrock.ts:299)
   - **Estimativa:** 2-3 horas
   - **Justificativa:** Melhora UX imediatamente para usu√°rios

#### üü° **PRIORIDADE M√âDIA** (Implementar em Seguida)

3. **Corre√ß√£o #3: Validar Disponibilidade Real na Certifica√ß√£o**
   - **Arquivos:**
     - [`backend/src/services/ai/certification/certification.service.ts`](backend/src/services/ai/certification/certification.service.ts:220)
   - **Estimativa:** 1-2 horas
   - **Justificativa:** Evita certificar modelos indispon√≠veis

4. **Corre√ß√£o #5: Melhorar Logging de Discrep√¢ncias**
   - **Arquivos:**
     - [`backend/src/services/ai/providers/bedrock.ts`](backend/src/services/ai/providers/bedrock.ts:217)
   - **Estimativa:** 1 hora
   - **Justificativa:** Facilita debug futuro

#### üü¢ **PRIORIDADE BAIXA** (Opcional)

5. **Corre√ß√£o #4: Adicionar Teste de Disponibilidade Real**
   - **Arquivos:**
     - [`backend/src/services/ai/certification/test-specs/base.spec.ts`](backend/src/services/ai/certification/test-specs/base.spec.ts:246)
   - **Estimativa:** 2-3 horas
   - **Justificativa:** Melhora confiabilidade mas n√£o √© cr√≠tico

---

### Checklist de Implementa√ß√£o

#### Fase 1: Detec√ß√£o de Erros (Corre√ß√£o #1)

- [ ] Adicionar `PROVISIONING_REQUIRED` ao enum `ErrorCategory`
- [ ] Adicionar regex de detec√ß√£o no `categorizeError()`
- [ ] Adicionar severidade `CRITICAL` para nova categoria
- [ ] Adicionar a√ß√µes sugeridas espec√≠ficas
- [ ] Adicionar mensagem amig√°vel
- [ ] Testar com erro real de throughput
- [ ] Validar que erro √© categorizado corretamente

#### Fase 2: Mensagens de Erro (Corre√ß√£o #2)

- [ ] Importar `categorizeError` no `bedrock.ts`
- [ ] Importar `ErrorCategory` no `bedrock.ts`
- [ ] Adicionar l√≥gica de categoriza√ß√£o no bloco de erro final
- [ ] Criar mensagens amig√°veis para cada categoria
- [ ] Adicionar sugest√µes de modelos alternativos
- [ ] Adicionar links para documenta√ß√£o AWS
- [ ] Testar com diferentes tipos de erro
- [ ] Validar que mensagens aparecem corretamente no frontend

#### Fase 3: Valida√ß√£o de Certifica√ß√£o (Corre√ß√£o #3)

- [ ] Adicionar verifica√ß√£o de `PROVISIONING_REQUIRED` na l√≥gica de status
- [ ] Marcar como `FAILED` quando detectado
- [ ] Adicionar nota explicativa em `qualityIssues`
- [ ] Testar com modelo que requer provisionamento
- [ ] Validar que modelo n√£o √© certificado incorretamente

#### Fase 4: Logging (Corre√ß√£o #5)

- [ ] Adicionar log detalhado antes de cada tentativa
- [ ] Adicionar log de sucesso ap√≥s invoca√ß√£o
- [ ] Adicionar log de erro com detalhes
- [ ] Testar logs em diferentes cen√°rios
- [ ] Validar que logs ajudam no debug

#### Fase 5: Teste de Disponibilidade (Corre√ß√£o #4 - Opcional)

- [ ] Criar novo teste `availability-check`
- [ ] Implementar 2 invoca√ß√µes consecutivas
- [ ] Detectar erros de provisionamento especificamente
- [ ] Adicionar metadata explicativa
- [ ] Adicionar teste √† su√≠te base
- [ ] Testar com modelos dispon√≠veis e indispon√≠veis
- [ ] Validar que teste detecta problemas reais

---

### Testes Necess√°rios

#### Testes Unit√°rios

1. **Error Categorizer:**
   ```typescript
   describe('categorizeError - PROVISIONING_REQUIRED', () => {
     it('should detect on-demand throughput error', () => {
       const error = 'Invocation of model ID with on-demand throughput isn\'t supported';
       const result = categorizeError(error);
       expect(result.category).toBe(ErrorCategory.PROVISIONING_REQUIRED);
       expect(result.severity).toBe(ErrorSeverity.CRITICAL);
     });
     
     it('should detect provisioned throughput required', () => {
       const error = 'Model requires provisioned throughput';
       const result = categorizeError(error);
       expect(result.category).toBe(ErrorCategory.PROVISIONING_REQUIRED);
     });
   });
   ```

2. **Bedrock Provider:**
   ```typescript
   describe('BedrockProvider - Error Messages', () => {
     it('should return user-friendly message for provisioning error', async () => {
       // Mock AWS SDK para retornar erro de throughput
       const provider = new BedrockProvider('us-east-1');
       const messages = [{ role: 'user', content: 'Hi' }];
       
       const chunks = [];
       for await (const chunk of provider.streamChat(messages, { 
         modelId: 'anthropic.claude-haiku-4-5-20251001-v1:0',
         apiKey: 'test:test'
       })) {
         chunks.push(chunk);
       }
       
       const errorChunk = chunks.find(c => c.type === 'error');
       expect(errorChunk).toBeDefined();
       expect(errorChunk.error).toContain('habilita√ß√£o pr√©via');
       expect(errorChunk.error).toContain('AWS Console');
     });
   });
   ```

#### Testes de Integra√ß√£o

1. **Certifica√ß√£o com Modelo Indispon√≠vel:**
   ```bash
   # Testar certifica√ß√£o de modelo que requer provisionamento
   npm run test:integration -- --grep "certification.*provisioning"
   ```

2. **Chat com Modelo Indispon√≠vel:**
   ```bash
   # Testar chat com modelo que requer provisionamento
   npm run test:integration -- --grep "chat.*provisioning"
   ```

#### Testes Manuais

1. **Cen√°rio 1: Modelo Requer Provisionamento**
   - Tentar certificar `anthropic.claude-haiku-4-5-20251001-v1:0`
   - Verificar que erro √© detectado como `PROVISIONING_REQUIRED`
   - Verificar que modelo √© marcado como `FAILED`
   - Verificar que mensagem amig√°vel √© exibida

2. **Cen√°rio 2: Modelo Sem Permiss√£o**
   - Usar credenciais AWS sem permiss√£o `bedrock:InvokeModel`
   - Verificar que erro √© detectado como `PERMISSION_ERROR`
   - Verificar que mensagem explica como adicionar permiss√£o

3. **Cen√°rio 3: Modelo N√£o Existe**
   - Tentar usar modelo inexistente
   - Verificar que erro √© detectado como `UNAVAILABLE`
   - Verificar que mensagem sugere verificar regi√£o

---

### Estimativa de Esfor√ßo Total

| Fase | Corre√ß√£o | Estimativa | Prioridade |
|------|----------|------------|------------|
| 1 | Detec√ß√£o de Erros | 1-2h | üî¥ Alta |
| 2 | Mensagens de Erro | 2-3h | üî¥ Alta |
| 3 | Valida√ß√£o de Certifica√ß√£o | 1-2h | üü° M√©dia |
| 4 | Logging | 1h | üü° M√©dia |
| 5 | Teste de Disponibilidade | 2-3h | üü¢ Baixa |
| - | Testes Unit√°rios | 2h | - |
| - | Testes de Integra√ß√£o | 1h | - |
| - | Testes Manuais | 1h | - |
| **TOTAL** | **Todas as corre√ß√µes** | **11-15h** | - |
| **M√çNIMO VI√ÅVEL** | **Corre√ß√µes #1 e #2** | **3-5h** | üî¥ Alta |

**Recomenda√ß√£o:**
- **Implementar Corre√ß√µes #1 e #2 imediatamente** (3-5h) - resolve o problema cr√≠tico de UX
- **Implementar Corre√ß√µes #3 e #5 em seguida** (2-3h) - melhora confiabilidade
- **Corre√ß√£o #4 √© opcional** - pode ser implementada depois se necess√°rio

---

## üéØ Resumo das Hip√≥teses Validadas

### ‚úÖ Hip√≥tese #1: Erro de Throughput/Provisionamento (CONFIRMADA)

**Evid√™ncia:**
- Erro menciona explicitamente "on-demand throughput isn't supported"
- Modelo requer habilita√ß√£o pr√©via na conta AWS
- Sistema n√£o detecta este tipo de erro especificamente

**Solu√ß√£o:**
- Adicionar categoria `PROVISIONING_REQUIRED`
- Melhorar mensagens de erro
- Validar disponibilidade na certifica√ß√£o

### ‚ö†Ô∏è Hip√≥tese #2: Timing/Estado da Conta AWS (PARCIALMENTE CONFIRMADA)

**Evid√™ncia:**
- Cache de certifica√ß√£o dura 7 dias
- Estado do modelo pode mudar entre certifica√ß√£o e uso

**Solu√ß√£o:**
- Teste de disponibilidade real (2 invoca√ß√µes consecutivas)
- Melhor logging para detectar mudan√ßas de estado

### ‚ùå Hip√≥tese #3: Diferen√ßa Sutil na Invoca√ß√£o (DESCARTADA)

**Evid√™ncia:**
- Certifica√ß√£o e chat usam mesma fun√ß√£o `streamChat()`
- Mesma l√≥gica de auto-test com 3 varia√ß√µes
- Mesma aplica√ß√£o de inference profiles

**Conclus√£o:**
- N√£o h√° discrep√¢ncia entre certifica√ß√£o e chat
- Problema √© de disponibilidade do modelo, n√£o de implementa√ß√£o

---

## üìö Refer√™ncias

### Documenta√ß√£o AWS

- [AWS Bedrock Model Access](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html)
- [AWS Bedrock Inference Profiles](https://docs.aws.amazon.com/bedrock/latest/userguide/cross-region-inference.html)
- [AWS Bedrock Provisioned Throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-throughput.html)
- [AWS Bedrock IAM Permissions](https://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html)
- [AWS Bedrock Models by Region](https://docs.aws.amazon.com/bedrock/latest/userguide/models-regions.html)

### Arquivos do Projeto

- [`backend/src/services/ai/certification/certification.service.ts`](backend/src/services/ai/certification/certification.service.ts:1) - Sistema de certifica√ß√£o
- [`backend/src/services/ai/certification/test-runner.ts`](backend/src/services/ai/certification/test-runner.ts:1) - Executor de testes
- [`backend/src/services/ai/certification/error-categorizer.ts`](backend/src/services/ai/certification/error-categorizer.ts:1) - Categorizador de erros
- [`backend/src/services/ai/providers/bedrock.ts`](backend/src/services/ai/providers/bedrock.ts:1) - Provider AWS Bedrock
- [`backend/src/services/ai/registry/model-registry.ts`](backend/src/services/ai/registry/model-registry.ts:1) - Registry de modelos
- [`backend/src/services/ai/registry/models/anthropic.models.ts`](backend/src/services/ai/registry/models/anthropic.models.ts:1) - Modelos Anthropic

---

## ‚úÖ Conclus√£o

### Problema Identificado

Modelos AWS Bedrock s√£o certificados mas falham no uso real devido a:
1. **Modelo requer provisionamento pr√©vio** (Provisioned Throughput ou Model Access Request)
2. **Sistema n√£o detecta erro de "on-demand throughput"** especificamente
3. **Mensagens de erro s√£o t√©cnicas demais** para o usu√°rio final

### Solu√ß√£o Proposta

1. **Adicionar categoria `PROVISIONING_REQUIRED`** para detectar erros de throughput
2. **Melhorar mensagens de erro** com explica√ß√µes claras e a√ß√µes acion√°veis
3. **Validar disponibilidade real** na certifica√ß√£o para evitar falsos positivos
4. **Melhorar logging** para facilitar debug de problemas futuros

### Pr√≥ximos Passos

1. ‚úÖ **Implementar Corre√ß√µes #1 e #2** (3-5h) - resolve problema cr√≠tico
2. ‚úÖ **Implementar Corre√ß√µes #3 e #5** (2-3h) - melhora confiabilidade
3. ‚ö†Ô∏è **Corre√ß√£o #4 √© opcional** - pode ser implementada depois

### Impacto Esperado

- ‚úÖ **UX melhorada drasticamente** - mensagens claras em portugu√™s
- ‚úÖ **Menos frustra√ß√£o do usu√°rio** - sabe exatamente o que fazer
- ‚úÖ **Menos suporte necess√°rio** - documenta√ß√£o e links inclu√≠dos
- ‚úÖ **Certifica√ß√£o mais confi√°vel** - detecta problemas reais
- ‚úÖ **Debug mais f√°cil** - logs detalhados

---

**Documento criado em:** 2026-01-27  
**√öltima atualiza√ß√£o:** 2026-01-27  
**Status:** üî¥ CR√çTICO - Aguardando Implementa√ß√£o