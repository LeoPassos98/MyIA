# Plano de Modulariza√ß√£o: chatController.ts

**Arquivo:** [`backend/src/controllers/chatController.ts`](../backend/src/controllers/chatController.ts)  
**Linhas Atuais:** 522 linhas (410 linhas de c√≥digo efetivo)  
**Meta:** ‚â§200 linhas (orquestra√ß√£o pura)  
**Conformidade:** [STANDARDS.md Se√ß√£o 15](../docs/STANDARDS.md:1199)

---

## üìä 1. An√°lise da Estrutura Atual

### 1.1 Responsabilidades Identificadas

O controller possui **1 endpoint complexo** (`sendMessage`) com m√∫ltiplas responsabilidades:

| Responsabilidade | Linhas | Complexidade |
|------------------|--------|--------------|
| **Valida√ß√£o de Entrada** | ~40 | M√©dia |
| **Preven√ß√£o de Duplicidade** | ~15 | Baixa |
| **Setup SSE** | ~10 | Baixa |
| **Gest√£o de Chat** | ~30 | M√©dia |
| **Constru√ß√£o de Contexto** | ~50 | Alta |
| **Montagem de Payload** | ~70 | Alta |
| **Valida√ß√£o de Tokens** | ~20 | M√©dia |
| **Auditoria (sentContext)** | ~30 | M√©dia |
| **Streaming** | ~120 | Alta |
| **Salvamento no Banco** | ~60 | M√©dia |
| **Gera√ß√£o de Embeddings** | ~30 | M√©dia |
| **Gera√ß√£o de T√≠tulo** | ~40 | M√©dia |

### 1.2 Problemas Identificados

#### ‚ùå Viola√ß√µes de STANDARDS.md

1. **Tamanho Excessivo (410 linhas)**
   - Limite: 200 linhas para controllers
   - Excesso: 105% acima do recomendado

2. **L√≥gica de Neg√≥cio no Controller**
   - Constru√ß√£o de contexto RAG (linhas 88-118)
   - Montagem de payload para IA (linhas 132-164)
   - Valida√ß√£o de tokens (linhas 166-182)
   - Constru√ß√£o de auditoria (linhas 186-212)
   - Processamento de stream (linhas 238-302)

3. **Responsabilidades Misturadas**
   - Controller faz valida√ß√£o de neg√≥cio
   - Controller constr√≥i payloads complexos
   - Controller gerencia SSE diretamente
   - Controller faz c√°lculos de custo

### 1.3 M√©tricas de Complexidade

```
Complexidade Ciclom√°tica: ~35 (Muito Alta)
Acoplamento: 10 depend√™ncias diretas
Coes√£o: Muito Baixa (m√∫ltiplas responsabilidades)
Testabilidade: Muito Dif√≠cil (l√≥gica entrela√ßada)
```

---

## üéØ 2. Proposta de Divis√£o em M√≥dulos

### 2.1 Estrutura de Diret√≥rios Proposta

```
backend/src/
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îî‚îÄ‚îÄ chatController.ts                       # 180 linhas (orquestra√ß√£o)
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ chat/
‚îÇ       ‚îú‚îÄ‚îÄ chatOrchestrator.ts                 # 200 linhas (coordena√ß√£o)
‚îÇ       ‚îú‚îÄ‚îÄ chatValidator.ts                    # 100 linhas (valida√ß√µes)
‚îÇ       ‚îú‚îÄ‚îÄ contextBuilder.ts                   # 150 linhas (constru√ß√£o contexto)
‚îÇ       ‚îú‚îÄ‚îÄ payloadBuilder.ts                   # 120 linhas (payload IA)
‚îÇ       ‚îú‚îÄ‚îÄ auditBuilder.ts                     # 100 linhas (sentContext)
‚îÇ       ‚îú‚îÄ‚îÄ streamProcessor.ts                  # 180 linhas (processamento stream)
‚îÇ       ‚îú‚îÄ‚îÄ messageRepository.ts                # 150 linhas (persist√™ncia)
‚îÇ       ‚îî‚îÄ‚îÄ titleGenerator.ts                   # 80 linhas (gera√ß√£o t√≠tulo)
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îî‚îÄ‚îÄ validators/
‚îÇ       ‚îî‚îÄ‚îÄ chatValidator.ts                    # 80 linhas (valida√ß√£o entrada)
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ chat/
        ‚îú‚îÄ‚îÄ duplicateRequestGuard.ts            # 60 linhas (anti-duplica√ß√£o)
        ‚îú‚îÄ‚îÄ sseHandler.ts                       # 70 linhas (SSE setup)
        ‚îî‚îÄ‚îÄ tokenValidator.ts                   # 80 linhas (valida√ß√£o tokens)
```

### 2.2 Responsabilidades por M√≥dulo

#### **chatController.ts** (180 linhas - Orquestra√ß√£o HTTP)
```typescript
// Apenas:
// 1. Receber requisi√ß√£o
// 2. Chamar orchestrator
// 3. Configurar SSE
// 4. Retornar resposta

export const chatController = {
  async sendMessage(req: AuthRequest, res: Response, next: NextFunction) {
    try {
      if (!req.userId) {
        res.status(401).json({ error: 'Unauthorized' });
        return;
      }
      
      // Valida√ß√£o de duplicidade
      const requestId = duplicateRequestGuard.generateId(req);
      if (duplicateRequestGuard.isProcessing(requestId)) {
        res.status(429).json({ error: 'Duplicate request blocked' });
        return;
      }
      
      duplicateRequestGuard.markAsProcessing(requestId);
      const cleanup = () => duplicateRequestGuard.release(requestId);
      
      // Setup SSE
      sseHandler.setupHeaders(res);
      const writeSSE = sseHandler.createWriter(res);
      
      try {
        // Orquestrar processamento
        await chatOrchestrator.processMessage({
          userId: req.userId,
          body: req.body,
          writeSSE,
          requestId: req.id
        });
        
        res.end();
      } finally {
        cleanup();
      }
    } catch (error) {
      if (!res.headersSent) next(error);
    }
  }
};
```

#### **chatOrchestrator.ts** (200 linhas - Coordena√ß√£o)
```typescript
// Orquestra todo o fluxo de processamento

export class ChatOrchestrator {
  async processMessage({
    userId,
    body,
    writeSSE,
    requestId
  }: ProcessMessageParams): Promise<void> {
    // 1. Validar entrada
    chatValidator.validateMessage(body);
    
    // 2. Gest√£o de chat
    const chat = await this.getOrCreateChat(userId, body.chatId, body.provider);
    const isNewChat = !body.chatId;
    
    // 3. Construir contexto
    const context = await contextBuilder.build({
      chatId: chat.id,
      message: body.message,
      isManualMode: body.context !== undefined,
      selectedMessageIds: body.selectedMessageIds,
      contextConfig: body.contextConfig,
      writeSSE
    });
    
    // 4. Salvar mensagem do usu√°rio
    const userMessage = await messageRepository.saveUserMessage({
      chatId: chat.id,
      content: body.message
    });
    
    writeSSE({ type: 'user_message_saved', userMessageId: userMessage.id });
    
    // 5. Construir payload para IA
    const payload = payloadBuilder.build({
      context,
      message: body.message,
      systemPrompt: body.contextConfig?.systemPrompt
    });
    
    // 6. Validar tokens
    tokenValidator.validate(payload, chat.provider, body.model);
    
    // 7. Construir auditoria
    const audit = auditBuilder.build({
      context,
      userMessageId: userMessage.id,
      config: {
        model: body.model,
        provider: chat.provider,
        strategy: body.strategy,
        params: { temperature: body.temperature, ... }
      }
    });
    
    // 8. Processar stream
    const result = await streamProcessor.process({
      payload,
      options: {
        providerSlug: chat.provider,
        modelId: body.model,
        userId,
        temperature: body.temperature,
        ...
      },
      writeSSE
    });
    
    // 9. Salvar resposta
    if (result.content) {
      const assistantMessage = await messageRepository.saveAssistantMessage({
        chatId: chat.id,
        content: result.content,
        provider: chat.provider,
        model: body.model,
        metrics: result.metrics,
        sentContext: audit
      });
      
      writeSSE({ type: 'telemetry', metrics: { ...result.metrics, messageId: assistantMessage.id } });
      
      // 10. Embeddings (fire and forget)
      this.generateEmbeddings(userMessage.id, assistantMessage.id, body.message, result.content);
      
      // 11. T√≠tulo (se novo chat)
      if (isNewChat) {
        this.generateTitle(chat.id, body.message, result.content, userId);
      }
    }
  }
  
  private async getOrCreateChat(userId: string, chatId?: string, provider?: string) {
    if (chatId) {
      const chat = await prisma.chat.findUnique({ where: { id: chatId, userId } });
      if (!chat) throw new Error('Chat not found');
      return chat;
    }
    return prisma.chat.create({ data: { userId, provider: provider || 'groq' } });
  }
  
  private async generateEmbeddings(userMsgId: string, assistantMsgId: string, userContent: string, assistantContent: string) {
    // Fire and forget
    embeddingService.generateForMessages(userMsgId, assistantMsgId, userContent, assistantContent)
      .catch(err => logger.error('Erro ao gerar embeddings', { error: err.message }));
  }
  
  private async generateTitle(chatId: string, userMessage: string, assistantMessage: string, userId: string) {
    // Fire and forget
    titleGenerator.generate(chatId, userMessage, assistantMessage, userId)
      .catch(err => logger.error('Erro ao gerar t√≠tulo', { error: err.message }));
  }
}
```

#### **contextBuilder.ts** (150 linhas - Constru√ß√£o de Contexto)
```typescript
// Constr√≥i contexto (hist√≥rico) para IA

export class ContextBuilder {
  async build({
    chatId,
    message,
    isManualMode,
    selectedMessageIds,
    contextConfig,
    writeSSE
  }: BuildContextParams): Promise<ContextResult> {
    if (isManualMode) {
      return this.buildManualContext(chatId, selectedMessageIds);
    }
    
    return this.buildAutoContext(chatId, message, contextConfig, writeSSE);
  }
  
  private async buildManualContext(chatId: string, selectedMessageIds?: string[]): Promise<ContextResult> {
    if (!selectedMessageIds || selectedMessageIds.length === 0) {
      return { messages: [], origins: {} };
    }
    
    const messages = await prisma.message.findMany({
      where: { id: { in: selectedMessageIds }, chatId },
      orderBy: { createdAt: 'asc' }
    });
    
    return {
      messages,
      origins: {} // Manual n√£o rastreia origem
    };
  }
  
  private async buildAutoContext(
    chatId: string,
    message: string,
    contextConfig: any,
    writeSSE: (data: any) => void
  ): Promise<ContextResult> {
    const report = await contextService.getHybridRagHistory(
      chatId,
      message,
      writeSSE,
      contextConfig
    );
    
    return {
      messages: report.finalContext,
      origins: report.messageOrigins
    };
  }
}
```

#### **payloadBuilder.ts** (120 linhas - Payload para IA)
```typescript
// Constr√≥i payload final para enviar √† IA

export class PayloadBuilder {
  build({
    context,
    message,
    systemPrompt
  }: BuildPayloadParams): PayloadForIA {
    const payload: Array<{ role: string; content: string }> = [];
    const pinnedStepIndices: number[] = [];
    const stepOrigins: Record<number, string> = {};
    
    // System prompt
    const finalSystemPrompt = systemPrompt || "Voc√™ √© uma IA √∫til e direta.";
    payload.push({ role: 'system', content: finalSystemPrompt });
    
    // Hist√≥rico
    context.messages.forEach(msg => {
      const currentIndex = payload.length;
      payload.push({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      });
      
      if (msg.isPinned) {
        pinnedStepIndices.push(currentIndex);
      }
      
      if (context.origins[msg.id]) {
        stepOrigins[currentIndex] = context.origins[msg.id];
      }
    });
    
    // Mensagem atual
    payload.push({ role: 'user', content: message });
    
    return {
      payload,
      pinnedStepIndices,
      stepOrigins,
      systemPrompt: finalSystemPrompt
    };
  }
}
```

#### **auditBuilder.ts** (100 linhas - sentContext)
```typescript
// Constr√≥i objeto de auditoria (sentContext) - STANDARDS ¬ß7

export class AuditBuilder {
  build({
    context,
    userMessageId,
    config
  }: BuildAuditParams): AuditObject {
    const isAutoMode = config.params.temperature === undefined;
    
    return {
      config_V47: {
        mode: config.isManualMode ? 'manual' : 'auto',
        model: config.model,
        provider: config.provider,
        timestamp: new Date().toISOString(),
        strategy: config.strategy || 'efficient',
        params: {
          mode: isAutoMode ? 'auto' : 'manual',
          temperature: config.params.temperature ?? 'auto',
          topP: config.params.topP ?? 'auto',
          topK: config.params.topK ?? 'auto',
          maxTokens: config.params.maxTokens ?? 'auto',
          memoryWindow: config.params.memoryWindow
        }
      },
      systemPrompt: context.systemPrompt,
      messageIds: context.messages.map(m => m.id),
      userMessageId,
      pinnedStepIndices: context.pinnedStepIndices,
      stepOrigins: context.stepOrigins,
      preflightTokenCount: contextService.countTokens(context.payload)
    };
  }
}
```

#### **streamProcessor.ts** (180 linhas - Processamento de Stream)
```typescript
// Processa stream da IA e trata erros

export class StreamProcessor {
  async process({
    payload,
    options,
    writeSSE
  }: ProcessStreamParams): Promise<StreamResult> {
    const stream = aiService.stream(payload, options);
    
    let fullContent = "";
    let finalMetrics: TelemetryMetrics | null = null;
    let streamError: string | null = null;
    
    // Watchdog para timeout
    const watchdog = this.createWatchdog(writeSSE);
    
    try {
      for await (const chunk of stream) {
        watchdog.reset();
        
        if (chunk.type === 'chunk') {
          fullContent += chunk.content;
        } else if (chunk.type === 'telemetry') {
          finalMetrics = chunk.metrics;
        } else if (chunk.type === 'error') {
          streamError = chunk.error;
        }
        
        writeSSE(chunk);
      }
      
      watchdog.clear();
      
      // Se houve erro, retornar early
      if (streamError) {
        return { content: null, metrics: null, error: streamError };
      }
      
      // Fallback de m√©tricas se necess√°rio
      if (!finalMetrics || finalMetrics.tokensIn === 0) {
        finalMetrics = this.calculateFallbackMetrics(payload, fullContent, options);
        writeSSE({ type: 'telemetry', metrics: finalMetrics });
      }
      
      return { content: fullContent, metrics: finalMetrics, error: null };
    } catch (error: any) {
      watchdog.clear();
      throw error;
    }
  }
  
  private createWatchdog(writeSSE: (data: any) => void) {
    let timer: NodeJS.Timeout | undefined;
    
    return {
      reset: () => {
        if (timer) clearTimeout(timer);
        timer = setTimeout(() => {
          writeSSE({ type: 'error', error: 'Timeout: API parou de responder' });
        }, 60000);
      },
      clear: () => {
        if (timer) clearTimeout(timer);
      }
    };
  }
  
  private calculateFallbackMetrics(payload: any[], content: string, options: any): TelemetryMetrics {
    const tokensIn = contextService.countTokens(payload);
    const tokensOut = contextService.encode(content);
    const providerInfo = getProviderInfo(options.modelId);
    const costInUSD = (tokensIn / 1_000_000) * providerInfo.costIn +
                      (tokensOut / 1_000_000) * providerInfo.costOut;
    
    return {
      provider: options.providerSlug,
      model: options.modelId,
      tokensIn,
      tokensOut,
      costInUSD,
      chatId: options.chatId
    };
  }
}
```

#### **messageRepository.ts** (150 linhas - Persist√™ncia)
```typescript
// Gerencia salvamento de mensagens no banco

export class MessageRepository {
  async saveUserMessage({ chatId, content }: SaveUserMessageParams): Promise<Message> {
    return prisma.message.create({
      data: {
        role: 'user',
        content,
        chatId
      }
    });
  }
  
  async saveAssistantMessage({
    chatId,
    content,
    provider,
    model,
    metrics,
    sentContext
  }: SaveAssistantMessageParams): Promise<Message> {
    const message = await prisma.message.create({
      data: {
        role: 'assistant',
        content,
        chatId,
        provider,
        model,
        tokensIn: metrics.tokensIn,
        tokensOut: metrics.tokensOut,
        costInUSD: metrics.costInUSD,
        sentContext: JSON.stringify(sentContext)
      }
    });
    
    // Log estruturado
    logger.info('TRACE_CREATED', {
      traceId: message.id,
      chatId,
      provider,
      model,
      tokensIn: metrics.tokensIn,
      tokensOut: metrics.tokensOut,
      costInUSD: metrics.costInUSD
    });
    
    return message;
  }
  
  async saveErrorMessage({
    chatId,
    error,
    provider,
    model,
    audit
  }: SaveErrorMessageParams): Promise<Message> {
    const errorContent = `[ERRO] ${error}`;
    const errorAudit = {
      ...audit,
      error: { message: error, type: 'stream_error' }
    };
    
    return prisma.message.create({
      data: {
        role: 'assistant',
        content: errorContent,
        chatId,
        provider,
        model,
        tokensIn: audit.preflightTokenCount || 0,
        tokensOut: 0,
        costInUSD: 0,
        sentContext: JSON.stringify(errorAudit)
      }
    });
  }
}
```

---

## üîÑ 3. Ordem de Implementa√ß√£o

### Fase 1: Extra√ß√£o de Utilit√°rios

1. ‚úÖ Criar `duplicateRequestGuard.ts`
2. ‚úÖ Criar `sseHandler.ts`
3. ‚úÖ Criar `tokenValidator.ts`

### Fase 2: Extra√ß√£o de Builders

4. ‚úÖ Criar `contextBuilder.ts`
5. ‚úÖ Criar `payloadBuilder.ts`
6. ‚úÖ Criar `auditBuilder.ts`

### Fase 3: Extra√ß√£o de Processadores

7. ‚úÖ Criar `streamProcessor.ts`
8. ‚úÖ Criar `messageRepository.ts`
9. ‚úÖ Criar `titleGenerator.ts`

### Fase 4: Cria√ß√£o do Orchestrator

10. ‚úÖ Criar `chatOrchestrator.ts`
    - Integrar todos os m√≥dulos
    - Testes de integra√ß√£o

### Fase 5: Refatora√ß√£o do Controller

11. ‚úÖ Refatorar `chatController.ts`
    - Reduzir para orquestra√ß√£o HTTP
    - Usar orchestrator

12. ‚úÖ Valida√ß√£o Final

---

## ‚ö†Ô∏è 4. Riscos e Mitiga√ß√µes

| Risco | Mitiga√ß√£o |
|-------|-----------|
| **Quebra de SSE** | Testes de integra√ß√£o espec√≠ficos |
| **Perda de auditoria** | Validar sentContext id√™ntico |
| **Degrada√ß√£o de performance** | Benchmarks antes/depois |
| **Regress√£o em embeddings** | Testes ass√≠ncronos |

---

## üìä 5. M√©tricas de Sucesso

### Antes
```
Arquivo: chatController.ts
Linhas: 522 (410 efetivas)
Complexidade: ~35
Testabilidade: Muito Dif√≠cil
```

### Depois (Meta)
```
chatController.ts: ‚â§180 linhas
chatOrchestrator.ts: 200 linhas
Builders: 3 √ó ~120 linhas
Processors: 3 √ó ~150 linhas
Utils: 3 √ó ~70 linhas

Total: ~1300 linhas (vs 522 original)
Ganho: +149% c√≥digo, mas 100% test√°vel e modular
```

---

## ‚úÖ 6. Crit√©rios de Aceita√ß√£o

- [ ] Controller ‚â§200 linhas
- [ ] Orchestrator ‚â§250 linhas
- [ ] Services ‚â§200 linhas cada
- [ ] SSE funciona identicamente
- [ ] sentContext preservado
- [ ] Embeddings funcionam
- [ ] T√≠tulo gerado corretamente
- [ ] Cobertura ‚â•80%

---

**Plano criado em:** 2026-02-07  
**Conformidade:** STANDARDS.md Se√ß√£o 15  
**Status:** Aguardando aprova√ß√£o
